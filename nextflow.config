manifest {
    name = 'lingualab/speechmetryflow'
    contributors = [
        [
            name: 'Christophe Bedetti',
            affiliation: 'Université de Montréal',
            email: '',
            github: '@cbedetti',
            contribution: ['author'], // List of contribution types ('author', 'maintainer' or 'contributor')
            orcid: '0000-0002-1443-8922',
        ],
    ]
    homePage = 'https://github.com/lingualab/speechmetryflow'
    description = 'Automated nextflow-based workflow designed to extract both audio and text metrics from speech tasks (like picture descriptions) at scale.'
    nextflowVersion = '>=24.10.4'
    version = '0.1.0dev'
}

params {
    // Pipeline options
    input = null
    audio_folder    = null
    text_folder     = null
    audio_extension = ".wav"
    text_extension  = ".txt"

    // Pipeline output
    output_dir = 'results'
    population_dir = [participant_id: 'Statistics']

    // Whisper options
    whisper_model = 'base'  // Can be: tiny, base, small, medium, large
    whisper_model_dir = null

    // Uhm-O-Meter options
    uhmometer {
        preprocessing          = "None"              // choices: "None", "Band pass (300..3300 Hz)", "Reduce noise"
        silence_threshold      = -25.0               // unit: dB
        minimum_dip_near_peak  = 2.0                 // unit: dB
        minimum_pause_duration = 0.3                 // unit: s
        detect_filled_pauses   = "yes"                // choices: "yes", "no"
        language               = "English"           // choices: "English", "Dutch"
        filled_pause_threshold =  1.00               // cut-off higher/lower
        data                   = "Praat Info window" // choices: "TextGrid(s) only", "Praat Info window", "Save as text file", "Table"
        data_collection_type   = "OverWriteData"     // choices: "OverWriteData", "AppendData"
        keep_objects           = "yes"               // when_processing_files, choices: choices: "yes", "no"
        output                 = "population_uhmometer_metrics.csv"
    }

    // Reports options
    report_timestamp = java.time.LocalDateTime.now().format(java.time.format.DateTimeFormatter.ofPattern("yyyyMMdd-HHmmss"))
}

process {
    publishDir = [
        path: { "${params.output_dir}/${meta.participant_id}/${task.process.split(':')[0]}" },
        mode: 'copy'
    ]
    errorStrategy = 'ignore'
}

report {
  enabled = true
  file = "log/report-${params.report_timestamp}.html"
}

dag {
  enabled = true
  file = "log/dag-${params.report_timestamp}.html"
  verbose = true
}

timeline {
  enabled = true
  file = "log/timeline-${params.report_timestamp}.html"
}

profiles {

    unf_elm {
        apptainer.enabled       = true
        apptainer.autoMounts    = true
        apptainer.runOptions    = "-B /data"
        process.cpus            = 20
        process.container       = "file:///data/brambati/local/containers/lingualab/speechmetryflow_0.0.5.sif"
        workDir                 = "/scratch/$USER/speechmetryflow/work"

        process {
            withName: "WHISPER" {
                container               = 'file:///data/brambati/local/containers/lingualab/openai-whisper-asr-webservice-v1.8.2.sif'
                params.whisper_model_dir = '/data/brambati/local/cache/whisper'
            }
        }

        process {
            withName: "UHMOMETER" {
                container               = 'file:///data/brambati/local/containers/lingualab/praat_v6.4.35.sif'
            }
        }
    }

}
