{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"speechmetryflow","text":"<p>Automated nextflow-based workflow designed to extract both audio and text metrics from speech tasks (like picture descriptions) at scale.</p>"},{"location":"#running","title":"Running","text":"<p><code>nextflow run lingualab/speechmetryflow -r {last_release_or_tag} --input participant_ids.csv</code></p> <p>Replace the <code>-r</code> option with the release you want to use</p>"},{"location":"#files-needed","title":"Files needed","text":""},{"location":"#participant_idscsv","title":"participant_ids.csv","text":"<p>This CSV file must contain at least 4 columns:</p> <ul> <li>participant_id is required for the pipeline to find your files. These files must begin by the participant_id. To specify the folder where your files are located, see nextflow.config.</li> <li>language: 2 choices, <code>en</code> or <code>fr</code>.</li> <li>sex: 2 choices, <code>male</code> or <code>female</code>.</li> <li>task: 2 choices, <code>cookie_theft</code> or <code>picnic</code>.</li> </ul> <p>Example:</p> participant_id language sex task sub-PKM8767 en male cookie_theft sub-SBK4467 en female picnic"},{"location":"#nextflowconfig","title":"nextflow.config","text":"<p>Example for elm server:</p> <pre><code>params {\n    audio_folder = \"/data/brambati/dataset/CCNA/derivatives/audio_extract\"\n    text_folder = \"/data/brambati/dataset/CCNA/derivatives/cookie_txt\"\n}\n</code></pre> <p>And then run:</p> <p><code>nextflow run lingualab/speechmetryflow -r {last_release_or_tag} -profile unf_elm --input participant_ids.csv</code></p>"},{"location":"#output","title":"output","text":"<p>The pipeline produces csv files in <code>results/Statistics</code> directory:</p> <ul> <li><code>population_lingualab_audio.csv</code>: metrics compute with <code>lingualabpy_lingualab_audio</code> from lingualabpy</li> <li><code>population_uhmometer_metrics.csv</code>: metrics compute with uhm-o-meter</li> <li><code>population_lingualab_text.csv</code>: metrics compute with Text2Variable</li> <li><code>population_opensmile_metrics_{feature_set}.csv</code>: metrics compute with opensmile</li> </ul>"},{"location":"lingualab-audio-phonetics/","title":"Extraction de variables phon\u00e9tiques","text":""},{"location":"lingualab-audio-phonetics/#definition-des-variables","title":"D\u00e9finition des variables","text":"Caract\u00e9ristique/famille de caract\u00e9ristique D\u00e9finition Fr\u00e9quence Fondamentale (F0) Variations de la tonalit\u00e9 de la voix, utile pour analyser l'intonation et le stress \u00e9motionnel. Intensit\u00e9 (Volume) Mesure du volume sonore, peut refl\u00e9ter l'emphase ou les changements \u00e9motionnels. Qualit\u00e9 de la Voix Caract\u00e9ristiques telles que la rugosit\u00e9, le souffle, la clart\u00e9 ou la nasalit\u00e9 de la voix. Spectrogramme Repr\u00e9sentation visuelle de l'\u00e9volution des fr\u00e9quences dans le temps, utile pour une analyse d\u00e9taill\u00e9e des caract\u00e9ristiques sonores. Fr\u00e9quences des Formants (F1, F2, etc.) Informations importantes sur les caract\u00e9ristiques des voyelles prononc\u00e9es. Modulation de Fr\u00e9quence et d'Amplitude Variations de la fr\u00e9quence et de l'amplitude au sein d'un m\u00eame phon\u00e8me ou mot. Harmonic-to-Noise Ratio (HNR) Rapport entre les composantes harmoniques et bruyantes de la voix, utile pour \u00e9valuer la qualit\u00e9 vocale. Jitter (Variabilit\u00e9 de Fr\u00e9quence) Variabilit\u00e9 de la fr\u00e9quence fondamentale d'un son, peut indiquer une tension ou un stress vocal. Shimmer (Variabilit\u00e9 d'Amplitude) Variabilit\u00e9 de l'amplitude des ondes sonores, li\u00e9e \u00e0 la stabilit\u00e9 et \u00e0 la qualit\u00e9 de la voix. Phonation Ces caract\u00e9ristiques se concentrent sur les aspects de la production vocale li\u00e9s \u00e0 l'activit\u00e9 des cordes vocales. Elles incluent des mesures comme la fr\u00e9quence fondamentale (pitch), le jitter et le shimmer, qui sont des indicateurs de la stabilit\u00e9 de la fr\u00e9quence et de l'amplitude de la voix. Articulation Ces caract\u00e9ristiques sont li\u00e9es \u00e0 la mani\u00e8re dont les mots et les sons sont form\u00e9s par le locuteur. Elles peuvent inclure des mesures de la dur\u00e9e des phon\u00e8mes, la vitesse de l'articulation et la dynamique des mouvements articulatoires. Prosodie La prosodie concerne le rythme, l'intonation et l'accentuation dans la parole. Les caract\u00e9ristiques prosodiques comprennent des mesures de l'intensit\u00e9, de la dur\u00e9e des syllabes et des motifs d'accentuation. Phonologie Ces caract\u00e9ristiques analysent les aspects de la parole li\u00e9s \u00e0 la structure phon\u00e9mique, comme les changements dans la qualit\u00e9 des voyelles ou des consonnes. <p>Praat, PyDub, librosa</p> <p>https://github.com/jcvasquezc/DisVoice</p>"},{"location":"lingualab-audio-phonetics/#noms-des-variables","title":"Noms des variables","text":"<ul> <li><code>F0_std</code></li> <li><code>duration</code></li> <li><code>f0_mean</code></li> <li><code>formants_1_mean</code></li> <li><code>formants_1_median</code></li> <li><code>formants_2_mean</code></li> <li><code>formants_2_median</code></li> <li><code>formants_3_mean</code></li> <li><code>formants_3_median</code></li> <li><code>formants_4_mean</code></li> <li><code>formants_4_median</code></li> <li><code>hnr</code></li> <li><code>jitter_ddp</code></li> <li><code>jitter_local</code></li> <li><code>jitter_local_absolute</code></li> <li><code>jitter_ppq5</code></li> <li><code>jitter_rap</code></li> <li><code>shimmer_apq11</code></li> <li><code>shimmer_apq3</code></li> <li><code>shimmer_apq5</code></li> <li><code>shimmer_dda</code></li> <li><code>shimmer_local</code></li> <li><code>shimmer_local_dB</code></li> </ul>"},{"location":"lingualab-text-lexical/","title":"Caract\u00e9ristiques lexicales","text":""},{"location":"lingualab-text-lexical/#parts-of-speech","title":"Parts-of-Speech","text":"<p>Classe grammaticale d\u2019un mot. La cat\u00e9gorisation en parties du discours (Parts-of-Speech ou POS) se r\u00e9f\u00e8re \u00e0 la classification des mots selon leur fonction grammaticale dans une phrase. Cela inclut la d\u00e9termination de la classe \u00e0 laquelle appartient chaque mot telles que les noms les pronoms les verbes les adverbes les adjectifs les pr\u00e9positions les d\u00e9terminants et les conjonctions.</p> <p>Nombre d\u2019occurrences de chaque classe grammaticale (noms pronoms verbes adverbes adjectifs pr\u00e9positions d\u00e9terminants conjonctions) dans l\u2019\u00e9chantillon. Calcul\u00e9 des 2 fa\u00e7ons suivantes : en nombre absolu et en relation au nombre total de mots dans l\u2019\u00e9chantillon.</p>"},{"location":"lingualab-text-lexical/#mots-de-classe-ouverte-et-fermee","title":"Mots de classe ouverte et ferm\u00e9e","text":"<p>Les \"mots de classes ouvertes\" et les \"mots de classes ferm\u00e9es\" sont deux cat\u00e9gories principales dans la classification des mots selon leur r\u00f4le dans la langue. Nombre total de mots de classe ouverte (noms verbes adjectifs adverbes) et de classe ferm\u00e9e (conjonctions pronoms d\u00e9terminants pr\u00e9positions) dans l\u2019\u00e9chantillon.</p>"},{"location":"lingualab-text-lexical/#mots-de-classes-ouvertes","title":"Mots de Classes Ouvertes","text":"<p>Ces mots constituent le contenu principal du discours. Ils sont appel\u00e9s \"ouverts\" car de nouveaux mots peuvent \u00eatre r\u00e9guli\u00e8rement ajout\u00e9s \u00e0 ces cat\u00e9gories.</p> <p>Ces mots incluent :</p> <ul> <li>Noms : Repr\u00e9sentent des personnes lieux objets id\u00e9es (ex. : pomme libert\u00e9).</li> <li>Verbes : D\u00e9signent des actions des \u00e9tats des occurrences (ex. : courir \u00eatre).</li> <li>Adjectifs : Qualifient ou quantifient les noms (ex. : rapide grand).</li> <li>Adverbes : Modifient des verbes des adjectifs ou d'autres adverbes (ex. : rapidement tr\u00e8s).</li> </ul>"},{"location":"lingualab-text-lexical/#mots-de-classes-fermees","title":"Mots de Classes Ferm\u00e9es","text":"<p>Ces mots remplissent une fonction grammaticale plut\u00f4t que de transmettre un contenu concret. Ils forment un ensemble relativement fixe et limit\u00e9 de termes.</p> <p>Ces mots incluent : - Conjonctions : Relient des mots phrases ou clauses (ex. : et mais). - Pronoms : Remplacent les noms (ex. : elle celui). - D\u00e9terminants : Pr\u00e9cisent les noms (ex. : le un). - Pr\u00e9positions : Relient un nom \u00e0 un autre \u00e9l\u00e9ment de la phrase (ex. : dans sur).</p>"},{"location":"lingualab-text-lexical/#exemple","title":"Exemple","text":"<p>Voici les \u00e9tapes g\u00e9n\u00e9rales pour compter les mots de classes ouvertes et ferm\u00e9es en Python en utilisant NLTK :</p> <ul> <li>T\u00e9l\u00e9charger les Ressources N\u00e9cessaires : Utilisez <code>nltk.download('punkt')</code> et <code>nltk.download('averaged_perceptron_tagger')</code>.</li> <li>Tokeniser le Texte et Appliquer le POS Tagging : Utilisez word_tokenize pour diviser le texte en mots et pos_tag pour appliquer le POS tagging \u00e0 chaque mot.</li> <li>Comptage des Mots : Comptez les occurrences de mots appartenant \u00e0 des classes ouvertes (noms verbes adjectifs adverbes) et ferm\u00e9es (conjonctions pronoms d\u00e9terminants pr\u00e9positions) et calculez ces nombres en termes absolus.</li> </ul>"},{"location":"lingualab-text-lexical/#ratio-de-differentes-parts-of-speech-et-types-de-mots","title":"Ratio de diff\u00e9rentes Parts-of-Speech et types de mots","text":"<p>Proportion de mots de diff\u00e9rentes classes grammaticales ou de diff\u00e9rents types de mots sur le nombre total de mots dans l\u2019\u00e9chantillon ou sur le nombre total de mots d\u2019une ou plusieurs autre(s) classe(s) grammaticale(s). </p> <p>Nombre total d\u2019occurrences d\u2019une classe grammaticale dans l\u2019\u00e9chantillon divis\u00e9 par le nombre total de mots dans l\u2019\u00e9chantillon ou par le nombre d\u2019occurrences d\u2019une ou plusieurs autre(s) classe(s) grammaticale(s).</p> <p>Les ratios suivants seront calcul\u00e9s : </p> <ul> <li>Pronoms/Noms + Pronoms </li> <li>Noms/Noms + Pronoms </li> <li>Noms/Noms + Verbes</li> <li>Verbes/Noms + Verbes</li> <li>Verbes avec inflexions/Nombre total de verbes</li> <li>Nombre de mots de classe ouverte/Nombre total de mots</li> <li>Nombre de mots de classe ferm\u00e9e/Nombre total de mots</li> <li>G\u00e9rondifs/Nombre total de verbes</li> <li>G\u00e9rondifs/Nombre total de mots</li> </ul>"},{"location":"lingualab-text-lexical/#verbes-legers","title":"Verbes l\u00e9gers","text":"<p>Un verbe l\u00e9ger est un terme linguistique d\u00e9signant un verbe qui pris isol\u00e9ment poss\u00e8de un contenu s\u00e9mantique limit\u00e9 ou g\u00e9n\u00e9rique mais qui lorsqu'il est combin\u00e9 avec d'autres mots (comme des noms des adjectifs ou des pr\u00e9positions) contribue \u00e0 cr\u00e9er une expression verbale avec un sens plus riche ou sp\u00e9cifique. Ces verbes souvent courants et polyvalents comme \"faire\" \"mettre\" \"prendre\" acqui\u00e8rent une signification plus nuanc\u00e9e et sp\u00e9cifique dans le contexte de leur combinaison avec d'autres \u00e9l\u00e9ments linguistiques. </p> <p>Nombre d\u2019occurrences des verbes suivants (\u00e0 l\u2019infinitif ou conjugu\u00e9s) dans l\u2019\u00e9chantillon : be, have, come, go, give, take, make, do, get, move, put.</p> <p>Calcul\u00e9 des deux fa\u00e7ons suivantes: - en nombre absolu - en relation au nombre total de verbes dans l\u2019\u00e9chantillon</p>"},{"location":"lingualab-text-lexical/#pronoms-deictiques","title":"Pronoms d\u00e9ictiques","text":"<p>Pronoms utilis\u00e9s pour faire r\u00e9f\u00e9rence directement aux caract\u00e9ristiques personnelles temporelles ou de localisation de l\u2019image \u00e0 d\u00e9crire. La signification sp\u00e9cifique de ces pronoms d\u00e9pend du contexte dans lequel ils sont utilis\u00e9s (Crystal 2011).</p> <p>Nombre total d\u2019occurrences des mots des quatre cat\u00e9gories suivantes dans l\u2019\u00e9chantillon:</p> <ul> <li>Deixis spatiale : this, that, here, there.</li> <li>Deixis personnelle : he, she, her, herself, him, himself.</li> <li>Deixis temporelle : then, now, soon, recently.</li> <li>Pronoms d\u00e9ictiques : somme des pronoms d\u00e9ictiques des trois cat\u00e9gories pr\u00e9c\u00e9dentes.</li> </ul> <p>Calcul\u00e9 des 2 fa\u00e7ons suivantes : - en nombre absolu - en relation au nombre total de mots dans l\u2019\u00e9chantillon</p>"},{"location":"lingualab-text-lexical/#termes-indefinis","title":"Termes ind\u00e9finis","text":"<p>Les \"termes ind\u00e9finis\" dans un contexte linguistique sont des mots utilis\u00e9s pour faire r\u00e9f\u00e9rence \u00e0 des objets des personnes ou des quantit\u00e9s de mani\u00e8re vague ou non sp\u00e9cifique sans d\u00e9signer un \u00e9l\u00e9ment pr\u00e9cis. Ils sont souvent employ\u00e9s pour parler de choses de mani\u00e8re g\u00e9n\u00e9rale ou pour indiquer une quantit\u00e9 ind\u00e9termin\u00e9e.</p> <p>Exemples:</p> <ul> <li>Objets ou Choses G\u00e9n\u00e9rales : thing, stuff\".</li> <li>Ind\u00e9finis Quantitatifs : little, much, few, many, several\".</li> <li>Ind\u00e9finis de Personnes : anyone, everyone, no one, someone, everybody, nobody.</li> <li> <p>Autres Ind\u00e9finis : another, the other, each, either, neither, both, other, others.</p> </li> <li> <p>Objets ou Choses G\u00e9n\u00e9rales : truc, chose.</p> </li> <li>Ind\u00e9finis Quantitatifs : peu, beaucoup, quelques, plusieurs.</li> <li>Ind\u00e9finis de Personnes : quelqu'un, tout le monde, personne, chacun, n'importe qui.</li> <li>Autres Ind\u00e9finis : autre, l'autre, chaque, ni l'un ni l'autre, les deux, d'autres.</li> </ul> <p>Nombre total d\u2019occurrences des termes suivants dans l\u2019\u00e9chantillon, calcul\u00e9 des 2 fa\u00e7ons suivantes :</p> <ul> <li>en nombre absolu</li> <li>en relation au nombre total de mots dans l\u2019\u00e9chantillon</li> </ul>"},{"location":"lingualab-text-lexical/#moving-average-type-token-ratio-mattr","title":"Moving Average Type-Token Ratio (MATTR)","text":"<p>Le Moving-Average Type-Token Ratio (MATTR) est une mesure en linguistique qui calcule la moyenne mobile pour tous les segments d'une longueur donn\u00e9e dans un texte. Pour un segment de 50 mots par exemple le Type-Token Ratio (TTR) est calcul\u00e9 sur les mots 1-50 2-51 3-52 etc... et les mesures de TTR r\u00e9sultantes sont moyenn\u00e9es pour produire la valeur finale de MATTR. Cette approche permet d'obtenir une mesure plus stable et repr\u00e9sentative de la diversit\u00e9 lexicale d'un texte car elle minimise l'impact de la longueur du texte sur le TTR\u200b\u200b.</p> <p>Calcul\u00e9 en d\u00e9pla\u00e7ant une fen\u00eatre de grandeur <code>x</code> \u00e0 travers le texte. Pour chaque fen\u00eatre un Type-Token Ratio est obtenu en divisant le nombre de mots uniques par le nombre total de mots dans la fen\u00eatre. Pour obtenir le MATTR global d\u2019un \u00e9chantillon la moyenne des TTR de chaque fen\u00eatre est calcul\u00e9e. La longueur de chaque fen\u00eatre sera d\u00e9termin\u00e9e en calculant le nombre de mots moyen dans tous les \u00e9chantillons de DS.</p> <p>Trois groupes de fen\u00eatre seront donc obtenus de fa\u00e7on \u00e0 ce que chaque fen\u00eatre contienne 10 25 et 40 mots (Covington &amp; McFall 2010).</p> <p>Un MATTR plus \u00e9lev\u00e9 indique une plus grande diversit\u00e9 lexicale (Covington &amp; McFall 2010)</p> <p>https://pypi.org/project/taaled/#:~:text=The Moving15</p>"},{"location":"lingualab-text-lexical/#statistique-r-de-honore","title":"Statistique R de Honor\u00e9","text":"<p>La statistique R de Honor\u00e9 est une mesure de la diversit\u00e9 lexicale qui prend en compte la longueur de l\u2019\u00e9chantillon le nombre de mots diff\u00e9rents utilis\u00e9s et le nombre de mots mentionn\u00e9s une seule fois.</p> <p>Elle est calcul\u00e9e selon la formule : <code>R=100\u00d7log(N)/(1\u2212(V1/V))</code></p> <ul> <li>N est le nombre total de mots dans l'\u00e9chantillon.</li> <li>V est le nombre de mots diff\u00e9rents dans l'\u00e9chantillon.</li> <li>V1 est le nombre de mots mentionn\u00e9s une seule fois.</li> </ul> <p>Cette mesure est particuli\u00e8rement utile pour analyser des textes plus longs car elle r\u00e9duit la sensibilit\u00e9 de la mesure de diversit\u00e9 lexicale \u00e0 la longueur du texte.</p> <p>Une statistique d\u2019Honor\u00e9 plus \u00e9lev\u00e9e indique une plus grande diversit\u00e9 lexicale.</p> <p>Pour op\u00e9rationnaliser et calculer la statistique R de Honor\u00e9 en Python vous devez d'abord tokeniser votre texte pour obtenir le nombre total de mots (N) compter le nombre de mots uniques (V) et identifier ceux qui n'apparaissent qu'une seule fois (V1). Ensuite vous pouvez appliquer la formule ci-dessus pour obtenir la valeur de R.</p>"},{"location":"lingualab-text-lexical/#index-w-de-brunet","title":"Index W de Brunet","text":"<p>Mesure de diversit\u00e9 lexicale reliant la longueur de l\u2019\u00e9chantillon au nombre de mots diff\u00e9rents utilis\u00e9s dans celui-ci.</p> <p>La formule de cet indice est : <code>W = N ^ (V ^ (-0.165))</code></p> <ul> <li>W est l'indice W de Brunet.</li> <li>N est le nombre total de mots dans le texte (aussi connu sous le nom de compte de tokens).</li> <li>V est le nombre total de mots uniques (aussi connu sous le nom de compte de types).</li> </ul> <p>Un index W de Brunet plus \u00e9lev\u00e9 indique une moins grande diversit\u00e9 lexicale (\u00e9chelle invers\u00e9e). Relativement peu affect\u00e9 par les variations dans la longueur de l\u2019\u00e9chantillon.</p>"},{"location":"lingualab-text-lexical/#familiarite","title":"Familiarit\u00e9","text":"<p>Degr\u00e9 avec lequel un mot est familier pour les locuteurs d\u2019une langue. \u00c9valuations subjectives de la familiarit\u00e9 obtenues des normes de Glasgow (Scott et al. 2019).</p> <p>La familiarit\u00e9 moyenne sera calcul\u00e9e pour tous les : mots, noms, verbes et adjectifs de l\u2019\u00e9chantillon.</p> <p>Des d\u00e9ficits s\u00e9mantiques et/ou d\u2019acc\u00e8s lexical pourraient se manifester par une utilisation accrue de mots \u00e9valu\u00e9s comme \u00e9tant tr\u00e8s familiers (Fraser et al. 2016).</p>"},{"location":"lingualab-text-lexical/#imageabilite","title":"Imageabilit\u00e9","text":"<p>Niveau d\u2019effort impliqu\u00e9 dans la g\u00e9n\u00e9ration d\u2019une image mentale du concept repr\u00e9sent\u00e9 par un mot. \u00c9valuations subjectives de l\u2019imageabilit\u00e9 obtenues des normes de Glasgow (Scott et al. 2019).</p> <p>L\u2019imageabilit\u00e9 moyenne sera calcul\u00e9e pour tous les : mots, noms, verbes et adjectifs de l\u2019\u00e9chantillon.</p> <p>Les \"Glasgow Norms\" sont un ensemble de notations normatives pour 5 553 mots anglais \u00e9valu\u00e9s sur neuf dimensions psycholinguistiques : l'excitation (arousal), la valence, la dominance, la concr\u00e9tude, l'imageabilit\u00e9, la familiarit\u00e9, l'\u00e2ge d'acquisition, la taille s\u00e9mantique, et l'association de genre. Ce corpus est unique en plusieurs aspects. Il est relativement large et fournit des normes sur un grand nombre de dimensions lexicales. Pour chaque sous-ensemble de mots les m\u00eames participants ont fourni des \u00e9valuations sur toutes les neuf dimensions. De plus le corpus contient un ensemble de 379 mots ambigus pr\u00e9sent\u00e9s seuls ou avec des informations s\u00e9lectionnant un autre sens. Les relations entre les dimensions des Glasgow Norms ont \u00e9t\u00e9 initialement \u00e9tudi\u00e9es en \u00e9valuant leurs corr\u00e9lations. Une analyse en composantes principales a r\u00e9v\u00e9l\u00e9 quatre facteurs principaux repr\u00e9sentant 82 % de la variance. La validit\u00e9 des Glasgow Norms a \u00e9t\u00e9 \u00e9tablie par des comparaisons avec 18 ensembles diff\u00e9rents de normes psycholinguistiques actuelles. Les Glasgow Norms offrent une ressource pr\u00e9cieuse en particulier pour les chercheurs \u00e9tudiant le r\u00f4le de la reconnaissance des mots dans la compr\u00e9hension du langage.</p> <p>https://pubmed.ncbi.nlm.nih.gov/30206797/</p>"},{"location":"lingualab-text-lexical/#concretude","title":"Concr\u00e9tude","text":"<p>Degr\u00e9 avec lequel le concept d\u00e9not\u00e9 par un mot fait r\u00e9f\u00e9rence \u00e0 une entit\u00e9 perceptible/tangible. \u00c9valuations subjectives de la concr\u00e9tude de Brysbaert et al. 2014.</p> <p>La concr\u00e9tude moyenne sera calcul\u00e9e pour tous les : mots, noms, verbes et adjectifs de l\u2019\u00e9chantillon.</p> <p>Les \u00e9valuations du caract\u00e8re concret sont pr\u00e9sent\u00e9es pour 37 058 mots anglais et 2 896 expressions de deux mots (telles que passage pi\u00e9ton et zoom avant) obtenues aupr\u00e8s de plus de 4 000 participants au moyen d'une \u00e9tude de normalisation utilisant le crowdsourcing sur Internet pour la collecte de donn\u00e9es.\u00a0Bien que les instructions soulignent que l'\u00e9valuation du caract\u00e8re concret des mots serait bas\u00e9e sur des exp\u00e9riences impliquant tous les sens et r\u00e9ponses motrices une comparaison avec les normes de caract\u00e8re concret existantes indique que les participants comme auparavant se sont largement concentr\u00e9s sur les exp\u00e9riences visuelles et haptiques.\u00a0L'ensemble de donn\u00e9es rapport\u00e9 est un sous-ensemble d'une liste compl\u00e8te de lemmes anglais et contient tous les lemmes connus par au moins 85 % des \u00e9valuateurs.\u00a0Il peut \u00eatre utilis\u00e9 dans des recherches futures comme liste de r\u00e9f\u00e9rence de lemmes anglais g\u00e9n\u00e9ralement connus.</p> <p>https://pubmed.ncbi.nlm.nih.gov/24142837/</p>"},{"location":"lingualab-text-lexical/#frequence-des-mots-dans-le-langage-courant","title":"Fr\u00e9quence des mots dans le langage courant","text":"<p>\u00c9valuation de la fr\u00e9quence avec laquelle un mot est utilis\u00e9 dans le langage courant par les locuteurs d\u2019une langue. Mesure objective de la fr\u00e9quence des mots tir\u00e9es du corpus SUBTLEX-US (Brysbaert &amp; New 2009).</p> <p>La fr\u00e9quence moyenne sera calcul\u00e9e pour tous les: mots, noms, verbes et adjectifs de l\u2019\u00e9chantillon.</p> <p>La base de donn\u00e9es SUBTLEX-US contient les fr\u00e9quences de mots bas\u00e9es sur les sous-titres de films comme d\u00e9velopp\u00e9 par Brysbaert et New en 2009. Cette base de donn\u00e9es offre une mesure objective de la fr\u00e9quence des mots en anglais am\u00e9ricain tir\u00e9e d'un large corpus de sous-titres. Elle inclut \u00e9galement des informations sur les parties du discours (PoS) et utilise l'\u00e9chelle de fr\u00e9quence de mots de Zipf. Cette approche fournit des donn\u00e9es plus repr\u00e9sentatives de l'utilisation des mots dans la langue parl\u00e9e courante compar\u00e9e aux fr\u00e9quences bas\u00e9es sur des textes \u00e9crits ou litt\u00e9raires. Elle est donc particuli\u00e8rement utile pour la recherche en psycholinguistique et en traitement automatique des langues.</p> <p>Les difficult\u00e9s \u00e0 acc\u00e9der \u00e0 des mots sp\u00e9cifiques r\u00e9sultent g\u00e9n\u00e9ralement en une sur-utilisation de mots avec une fr\u00e9quence \u00e9lev\u00e9e (Wang et al. 2021). https://osf.io/djpqz/</p>"},{"location":"lingualab-text-lexical/#valence","title":"Valence","text":"<p>Degr\u00e9 d\u2019agr\u00e9abilit\u00e9 des \u00e9motions invoqu\u00e9es par un mot. \u00c9valuations subjectives de la valence de Warriner et al. 2013.</p> <p>La valence moyenne sera calcul\u00e9e pour tous les: mots, noms, verbes et adjectifs de l\u2019\u00e9chantillon.</p> <p>L'\u00e9tude de Warriner et al. de 2013 a impliqu\u00e9 l'\u00e9valuation subjective de la valence de l'excitation et de la dominance pour 13 915 lemmes en anglais. Cette recherche a \u00e9t\u00e9 r\u00e9alis\u00e9e par un groupe de 1 827 participants qui ont \u00e9valu\u00e9 la valence \u00e9motionnelle de ces mots dans une \u00e9tude de notation en ligne, https://www.frontiersin.org/journals/communication/articles/10.3389/fcomm.2021.770497/full.</p> <p>La valence dans ce contexte se r\u00e9f\u00e8re \u00e0 la qualit\u00e9 affective d'un mot indiquant s'il \u00e9voque des sentiments positifs ou n\u00e9gatifs. Les chercheurs ont trouv\u00e9 une corr\u00e9lation forte entre la valence et la dominance sugg\u00e9rant que les stimuli ne pourraient pas \u00eatre facilement identifi\u00e9s comme variant en valence tout en restant constants en dominance, https://www.sciencedirect.com/science/article/pii/S0001691821001098. Les r\u00e9sultats ont montr\u00e9 que l'\u00e9cart-type moyen des \u00e9valuations de valence \u00e9tait de 168 tandis que celui des \u00e9valuations d'excitation pour les m\u00eames mots \u00e9tait de 230 indiquant une plus grande variabilit\u00e9 dans les \u00e9valuations d'excitation que de valence, https://www.sciencedirect.com/science/article/pii/S0346251X19302039.</p> <p>Ces normes de valence d'excitation et de dominance pour les mots anglais sont utilis\u00e9es par les chercheurs travaillant sur les \u00e9motions et les humeurs la reconnaissance et la m\u00e9moire des mots ainsi que l'analyse du sentiment bas\u00e9e sur le texte, https://pubmed.ncbi.nlm.nih.gov/23404613/. La recherche de Warriner et al. contribue ainsi de mani\u00e8re significative \u00e0 notre compr\u00e9hension de la mani\u00e8re dont les mots sont per\u00e7us \u00e9motionnellement et de leur impact sur divers domaines de la psycholinguistique.</p>"},{"location":"lingualab-text-lexical/#base-de-donnees-francaises","title":"Base de donn\u00e9es fran\u00e7aises","text":"<p>Voici les banques de donn\u00e9es pour la langue fran\u00e7aise : Open Lexicon FR, Les bases de donn\u00e9es lexicales en fran\u00e7ais</p>"},{"location":"lingualab-text-lexical/#noms-des-variables","title":"Noms des variables","text":"<ul> <li><code>Mots_de_classe_ouverte</code></li> <li><code>Mots_de_classe_fermee</code></li> <li><code>Nombre_de_gerondifs</code></li> <li><code>Pronoms/(Noms+Pronoms)</code></li> <li><code>Noms/(Noms+Pronoms)</code></li> <li><code>Noms/(Noms+Verbes)</code></li> <li><code>Verbes/(Noms+Verbes)</code></li> <li><code>Verbes_avec_inflexions/Total_Verbes</code></li> <li><code>Mots_de_classe_ouverte/Total_Mots</code></li> <li><code>Mots_de_classe_fermee/Total_Mots</code></li> <li><code>Gerondifs/Total_Verbes</code></li> <li><code>Gerondifs/Total_Mots</code></li> <li><code>Nombre_de_pronoms_deictiques</code></li> <li><code>Nombre_de_pronoms_deictiques_spatiaux</code></li> <li><code>Nombre_de_pronoms_deictiques_personnels</code></li> <li><code>Nombre_de_pronoms_deictiques_temporels</code></li> <li><code>Nombre_de_termes_indefinis</code></li> <li><code>Ratio_termes_indefinis</code></li> <li><code>MATTR_10</code></li> <li><code>MATTR_25</code></li> <li><code>MATTR_40</code></li> <li><code>Nombre_de_mots_uniques</code></li> <li><code>Statistique_R_de_Honore</code></li> <li><code>Familiarite_moyenne_mots</code></li> <li><code>Familiarite_moyenne_noms</code></li> <li><code>Familiarite_moyenne_verbes</code></li> <li><code>Familiarite_moyenne_adjectifs</code></li> <li><code>Imageabilite_moyenne_mots</code></li> <li><code>Imageabilite_moyenne_noms</code></li> <li><code>Imageabilite_moyenne_verbes</code></li> <li><code>Imageabilite_moyenne_adjectifs</code></li> <li><code>Concretude_moyenne_mots</code></li> <li><code>Concretude_moyenne_noms</code></li> <li><code>Concretude_moyenne_verbes</code></li> <li><code>Concretude_moyenne_adjectifs</code></li> <li><code>Frequence_moyenne_mots</code></li> <li><code>Frequence_moyenne_noms</code></li> <li><code>Frequence_moyenne_verbes</code></li> <li><code>Frequence_moyenne_adjectifs</code></li> <li><code>Valence_moyenne_mots</code></li> <li><code>Valence_moyenne_noms</code></li> <li><code>Valence_moyenne_verbes</code></li> <li><code>Valence_moyenne_adjectifs</code></li> <li><code>Brunet_W_indice</code></li> </ul>"},{"location":"lingualab-text-pragmatic/","title":"Caract\u00e9ristiques pragmatiques","text":""},{"location":"lingualab-text-pragmatic/#coherence-locale","title":"Coh\u00e9rence locale","text":"<p>Similarit\u00e9 s\u00e9mantique d\u2019une phrase avec la pr\u00e9c\u00e9dente.</p> <p>Le score de similarit\u00e9 s\u00e9mantique moyen souvent calcul\u00e9 par la distance cosinus est une mesure courante en traitement automatique des langues (NLP) pour \u00e9valuer la proximit\u00e9 s\u00e9mantique entre des phrases.</p> <p>La distance cosinus est une mesure de similarit\u00e9 entre deux vecteurs dans un espace multidimensionnel qui se calcule en mesurant le cosinus de l'angle entre eux. En NLP, cette mesure est souvent utilis\u00e9e pour comparer des vecteurs de mots ou de phrases o\u00f9 les vecteurs repr\u00e9sentent la distribution s\u00e9mantique des termes. La fonction <code>cosine_similarity</code> de la biblioth\u00e8que scikit-learn est une impl\u00e9mentation de cette mesure.</p> <p>Des valeurs plus \u00e9lev\u00e9es indiquent une plus grande similarit\u00e9 et une moins grande distance s\u00e9mantique. Des valeurs plus basses indiquent une moins grande similarit\u00e9 et une plus grande distance s\u00e9mantique.</p>"},{"location":"lingualab-text-pragmatic/#mots-denotant-lincertitude","title":"Mots d\u00e9notant l\u2019incertitude","text":"<p>Mots d\u00e9notant une incertitude \u00e0-propos de la nature d\u2019un \u00e9l\u00e9ment de l\u2019image \u00e0 d\u00e9crire.</p> <p>Nombre d\u2019occurences des mots suivants dans l\u2019\u00e9chantillon : \"think\", \"look\", \"like\", \"kind\", \"seem\", \"maybe\", \"can\", \"something\".</p> <p>Calcule\u0301 des deux fac\u0327ons suivantes :</p> <ul> <li>en nombre absolu </li> <li>en relation au nombre total de mots l\u2019e\u0301chantillon</li> </ul> <p>Liste de mots inspir\u00e9e par (Garrard et al., 2014), Il faut faire une version fran\u00e7aise.</p>"},{"location":"lingualab-text-pragmatic/#difficultes-a-trouver-les-bons-mots","title":"Difficult\u00e9s \u00e0 trouver les bons mots","text":"<p>Utilisation de mots indiquant des difficult\u00e9s d\u2019acc\u00e8s lexical.</p> <p>Nombre d\u2019instances des mots suivants dans l\u2019\u00e9chantillon : \"know\", \"remember\", \"unable\".</p> <p>Calcule\u0301 des deux fac\u0327ons suivantes :</p> <ul> <li>en nombre absolu </li> <li>en relation au nombre total de mots l\u2019e\u0301chantillon</li> </ul> <p>Liste de mots inspir\u00e9e par (Garrard et al., 2014) et (Rentoumi et al., 2014), Il faut faire une version fran\u00e7aise.</p>"},{"location":"lingualab-text-pragmatic/#connotation-du-discours","title":"Connotation du discours","text":"<p>\u00c9motions g\u00e9n\u00e9r\u00e9es par le discours. D\u00e9pend de la valence moyenne des mots du discours. Le score de valence moyen de tous les mots de l\u2019\u00e9chantillon sera obtenu lors de l\u2019extraction des variables psycholinguistiques. Pour chaque mot les scores possibles se situent entre 1 et 9. Un score plus \u00e9lev\u00e9 indique qu\u2019un mot a une connotation davantage positive alors qu\u2019un score plus bas indique une connotation davantage n\u00e9gative. </p> <ul> <li>Si la valence moyenne est sup\u00e9rieure ou \u00e9gale \u00e0 5, l\u2019\u00e9tiquette \"connotation positive\" sera donn\u00e9e au discours.</li> <li>Si la valence moyenne est sup\u00e9rieure ou \u00e9gale \u00e0 4 et inf\u00e9rieure \u00e0 5, l\u2019\u00e9tiquette \"connotation neutre\" sera donn\u00e9e au discours.</li> <li>Si la valence moyenne est inf\u00e9rieure \u00e0 4, l\u2019\u00e9tiquette \"connotation n\u00e9gative\" sera donn\u00e9e au discours.</li> </ul>"},{"location":"lingualab-text-pragmatic/#expressions-formulaiques","title":"Expressions formulaiques","text":"<p>Expressions ayant une forme fixe et une signification non-litt\u00e9rale avec des nuances attitudinales.</p> <p>Nombre total d\u2019occurrences des expressions formulaiques suivantes dans l\u2019\u00e9chantillon : \"well\", \"so\", \"I guess\", \"you know\", \"as it is\", \"as it were\". (Van Lancker Sidtis et al. 2015)</p> <p>Calcule\u0301 des deux fac\u0327ons suivantes : </p> <ul> <li>en nombre absolu </li> <li>en relation au nombre total de mots l\u2019e\u0301chantillon</li> </ul>"},{"location":"lingualab-text-pragmatic/#modalisations","title":"Modalisations","text":"<p>Opinions d\u2019un individu concernant le contenu de sa description (ou ce qui se passe sur l\u2019image \u00e0 d\u00e9crire) incluant les doutes et les inqui\u00e9tudes par rapport \u00e0 sa production.</p> <p>Nombre total d\u2019occurrences des expressions suivantes dans l\u2019\u00e9chantillon : \"I think\", \"In my opinion\", \"of course\", \"naturally\", \"unsure\", \"likely\", \"could be that\", \"unfortunately\", \"surely\". (Boschi et al. 2017, Boy\u00e9 et al. 2014)</p> <p>Calcule\u0301 des deux fac\u0327ons suivantes : </p> <ul> <li>en nombre absolu </li> <li>en relation au nombre total de mots l\u2019e\u0301chantillon</li> </ul>"},{"location":"lingualab-text-pragmatic/#mots-de-remplissage","title":"Mots de remplissage","text":"<p>Mots ou groupes de mots utilis\u00e9s pour mettre l\u2019accent sur ce qui sera dit ou a \u00e9t\u00e9 dit ou qui signalent qu\u2019un individu r\u00e9fl\u00e9chi \u00e0 ce qu\u2019il dira ensuite.</p> <p>Nombre total de fois o\u00f9 les expressions \"you know\", \"I mean\" sont mentionn\u00e9es dans l\u2019\u00e9chantillon.</p> <p>Calcule\u0301 des deux fac\u0327ons suivantes : </p> <ul> <li>en nombre absolu </li> <li>en relation au nombre total de mots l\u2019e\u0301chantillon</li> </ul> <p>Pourraient donner de l\u2019information sur la capacit\u00e9 d\u2019acc\u00e8s lexical d\u2019un individu.</p> <p>Note: Ce tableau se veut une version modifie\u0301e de celui qui est retrouve\u0301 dans Slegers et al. 2021 et de Pellerin Sophie.</p>"},{"location":"lingualab-text-pragmatic/#noms-des-variables","title":"Noms des variables","text":"<ul> <li><code>Coherence_locale</code></li> <li><code>Sentiment-valence</code></li> <li><code>Emotion</code></li> <li><code>Nombre_de_mots_incertitude</code></li> <li><code>Frequence_relative_mots_incertitude</code></li> <li><code>Nombre_de_mots_difficulte_acces_lexical</code></li> <li><code>Frequence_relative_mots_difficulte_acces_lexical</code></li> <li><code>Nombre_de_mots_expression_formulaiques</code></li> <li><code>Frequence_relative_mots_expression_formulaiques</code></li> <li><code>Nombre_de_mots_modalisations</code></li> <li><code>Frequence_relative_mots_modalisations</code></li> <li><code>Nombre_de_mots_de_remplissage</code></li> <li><code>Frequence_relative_mots_de_remplissage</code></li> </ul>"},{"location":"lingualab-text-production/","title":"Production de la parole","text":""},{"location":"lingualab-text-production/#definitions","title":"D\u00e9finitions","text":""},{"location":"lingualab-text-production/#lemmatisation","title":"Lemmatisation","text":"<p>Un lemme dans le contexte de la linguistique est la forme canonique de base ou de r\u00e9f\u00e9rence d'un mot. En d'autres termes c'est la forme sous laquelle un mot est inscrit dans un dictionnaire ou utilis\u00e9 pour repr\u00e9senter toutes les variantes flexionnelles d'un mot. L'id\u00e9e est de regrouper les diff\u00e9rentes formes d'un mot (comme les temps pass\u00e9s futurs les pluriels etc.) sous une seule forme standardis\u00e9e.</p> <p>Les lemmes ne sont pas des marqueurs de ponctuation ou des pauses remplies (comme \"hmm\" ou \"euh\") qui sont g\u00e9n\u00e9ralement omis dans l'analyse lexicale car ils ne portent pas de sens lexical sp\u00e9cifique.</p> <p>Exemples:</p> <ul> <li>\"suis\", \"es\", \"est\", \"sommes\", \"\u00eates\", \"sont\" est \"\u00eatre\"</li> <li>\"chien\", \"chiens\", \"chienne\", \"chiennes\", est \"chien\"</li> <li> <p>\"meilleur\", \"mieux\" est \"bon\"</p> </li> <li> <p>Processus: La lemmatisation implique une analyse morphologique compl\u00e8te des mots pour en d\u00e9duire leur forme canonique ou lemme. La lemmatisation tient compte du contexte du mot de son genre de son nombre et de son temps pour d\u00e9terminer sa forme de base.</p> </li> <li>Exemple: Reprenant votre exemple le mot \u00ab trouvez \u00bb est ramen\u00e9 \u00e0 sa forme de base \u00ab trouver \u00bb. Contrairement au stemming le r\u00e9sultat de la lemmatisation est toujours un mot valide et reconnaissable.</li> <li>Usage: La lemmatisation est souvent utilis\u00e9e dans des situations o\u00f9 la pr\u00e9cision est cruciale comme dans les syst\u00e8mes de compr\u00e9hension du langage naturel ou les applications linguistiques o\u00f9 la compr\u00e9hension du contexte et la pr\u00e9cision s\u00e9mantique sont importantes.</li> </ul>"},{"location":"lingualab-text-production/#phoneme","title":"Phon\u00e8me","text":"<p>Un phon\u00e8me est une unit\u00e9 sonore de base dans une langue qui permet de distinguer un mot d'un autre. C'est la plus petite unit\u00e9 de son qui peut changer le sens d'un mot. Les phon\u00e8mes sont des concepts abstraits utilis\u00e9s pour analyser la fa\u00e7on dont les sons fonctionnent dans une langue particuli\u00e8re. Ils ne sont pas les sons eux-m\u00eames mais plut\u00f4t des cat\u00e9gories de sons qui peuvent \u00eatre prononc\u00e9s de diff\u00e9rentes mani\u00e8res par diff\u00e9rents locuteurs tout en \u00e9tant per\u00e7us comme le m\u00eame son.</p> <p>En fran\u00e7ais, les sons /p/ et /b/ sont des phon\u00e8mes distincts car ils diff\u00e9rencient des mots comme \"patte\" et \"batte\". Le phon\u00e8me /k/ est pr\u00e9sent dans les mots \"caf\u00e9\" et \"quai\" bien que le son soit produit de mani\u00e8re diff\u00e9rente dans chaque mot (avec une lettre diff\u00e9rente).</p> <p>En anglais les phon\u00e8mes /t/ et /d/ diff\u00e9rencient les mots \"tap\" (taper) et \"dap\" (un mot invent\u00e9 mais qui sonne diff\u00e9remment gr\u00e2ce au phon\u00e8me initial diff\u00e9rent).</p>"},{"location":"lingualab-text-production/#tokenisation","title":"Tokenisation","text":"<p>D\u00e9coupage du texte en plusieurs pi\u00e8ces appel\u00e9s\u00a0tokens.</p> <p>Example: \"Vous trouverez en pi\u00e8ce jointe le document en question\" donne \"Vous\", \"trouverez\", \"en\", \"pi\u00e8ce\", \"jointe\", \"le\", \"document\", \"en\", \"question\"</p>"},{"location":"lingualab-text-production/#stemming","title":"Stemming","text":"<ol> <li>Processus: Le stemming consiste \u00e0 couper les extr\u00e9mit\u00e9s (sufffixes et parfois pr\u00e9fixes) des mots pour atteindre une forme simplifi\u00e9e. Ce processus est g\u00e9n\u00e9ralement heuristique et ne tient pas compte du contexte ou de la morphologie compl\u00e8te des mots. Il se base sur des r\u00e8gles simples et fixes pour tronquer les mots.</li> <li>Exemple: Dans votre exemple \u00ab trouverez \u00bb devient \u00ab trouv \u00bb. Ici le suffixe \u00ab -erez \u00bb est enlev\u00e9 pour arriver \u00e0 la racine \u00ab trouv \u00bb. Cette racine n'est pas n\u00e9cessairement un mot valide en soi.</li> <li>Usage: Le stemming est souvent utilis\u00e9 dans les syst\u00e8mes de recherche et de filtrage o\u00f9 la pr\u00e9cision n'est pas critique mais o\u00f9 la vitesse et la simplicit\u00e9 du processus sont importantes.</li> </ol>"},{"location":"lingualab-text-production/#lemmatisation_1","title":"Lemmatisation","text":"<p>Cela consiste \u00e0 r\u00e9aliser la m\u00eame t\u00e2che que le stemming mais en utilisant un vocabulaire et une analyse fine de la construction des mots. La\u00a0lemmatisation\u00a0permet donc de supprimer uniquement les terminaisons inflexibles et donc \u00e0\u00a0isoler la forme canonique du mot connue sous le nom de lemme.</p>"},{"location":"lingualab-text-production/#similarite-semantique","title":"Similarit\u00e9 S\u00e9mantique","text":"<p>La similarit\u00e9 s\u00e9mantique mesure \u00e0 quel point deux mots ou concepts sont proches en termes de signification. Dans le contexte des word embeddings cela se traduit souvent par la proximit\u00e9 de leurs vecteurs dans l'espace vectoriel.</p>"},{"location":"lingualab-text-production/#word-embedding","title":"Word Embedding","text":"<p>Le Word Embedding (ou plongement lexical en fran\u00e7ais) est une m\u00e9thode d'encodage qui vise \u00e0 repr\u00e9senter les mots ou les phrases d\u2019un texte par des vecteurs de nombres r\u00e9els d\u00e9crit dans un mod\u00e8le vectoriel (ou Vector Space Model).</p> <p>D'une mani\u00e8re plus simple chaque mot du vocabulaire V \u00e9tudi\u00e9 sera repr\u00e9sent\u00e9 par un vecteurs de taille m. Le principe du Word Embedding est de projeter chacun de ces mots dans un espace vectoriel d'une taille fixe N (N \u00e9tant diff\u00e9rent de m). C'est-\u00e0-dire quelle que soit la taille du vocabulaire on devra \u00eatre capable de projeter un mot dans son espace.</p>"},{"location":"lingualab-text-production/#modeles-dembedding","title":"Mod\u00e8les d'Embedding","text":"<p>CBOW (Continuous Bag-of-Words) : Dans ce mod\u00e8le le mot cible est pr\u00e9dit \u00e0 partir de mots environnants. Il prend en compte le contexte repr\u00e9sent\u00e9 par les mots voisins pour pr\u00e9dire le mot cible\u200b\u200b.</p> <p>Skip-Gram : Inverse du CBOW, ce mod\u00e8le pr\u00e9dit le contexte d'un mot donn\u00e9. Il est efficace pour repr\u00e9senter des mots ou des phrases rares\u200b\u200b.</p>"},{"location":"lingualab-text-production/#arbre-de-dependance","title":"Arbre de d\u00e9pendance","text":"<p>Dans une grammaire de d\u00e9pendance une phrase est repr\u00e9sent\u00e9e sous la forme d'un arbre. Chaque mot dans la phrase est un n\u0153ud de cet arbre. Les liens (ou arcs) entre ces mots repr\u00e9sentent des relations syntaxiques.</p>"},{"location":"lingualab-text-production/#variables","title":"Variables","text":""},{"location":"lingualab-text-production/#longueur-de-lechantillon","title":"Longueur de l\u2019\u00e9chantillon","text":"<p>Soit le nombre total de mots dans l\u2019\u00e9chantillon. C'est le nombre total de lemmas qui ne sont pas des marqueurs de ponctuation incluant les pauses remplies (ex. hmmm).</p>"},{"location":"lingualab-text-production/#fragments-de-mots","title":"Fragments de mots","text":"<p>Production de seulement une partie des phon\u00e8mes d\u2019un mot sans remplacements de sons ou erreurs d\u2019articulation. Peut \u00eatre suivi de la production compl\u00e8te du mot ou non. Un fragment de mot est une portion d'un mot qui contient un ou plusieurs phon\u00e8mes de ce mot mais pas l'enti\u00e8ret\u00e9 de ses phon\u00e8mes. En d'autres termes c'est une partie d'un mot pas le mot complet.</p> <ul> <li>Identification des Fragments : Dans l'\u00e9chantillon de parole ou de texte vous cherchez des occurrences o\u00f9 seulement une partie d'un mot est prononc\u00e9e ou \u00e9crite. Cela peut \u00eatre le d\u00e9but d'un mot la fin ou m\u00eame le milieu tant que ce n'est pas le mot entier.</li> <li>Comptage des Fragments : Vous comptez ensuite le nombre total de ces fragments dans l'\u00e9chantillon. Chaque occurrence d'un fragment de mot est compt\u00e9e comme une unit\u00e9 distincte.</li> <li>Exclusion des Erreurs de Prononciation et Remplacements de Sons : Il est important de noter que les fragments de mots ne doivent pas \u00eatre confondus avec des erreurs de prononciation ou des substitutions de sons. Ce sont des occurrences sp\u00e9cifiques o\u00f9 les phon\u00e8mes manquants ne sont pas remplac\u00e9s par d'autres sons ou erreurs.</li> <li>Exemple : \"I her kitchkitchen\" Un exemple de cela serait dans un \u00e9chantillon de parole o\u00f9 quelqu'un commence \u00e0 dire un mot mais s'arr\u00eate avant de le finir comme commencer \u00e0 dire \"incompr\u00e9hens...\" au lieu de \"incompr\u00e9hensible\". Chaque fois que cela se produit cela compterait comme un fragment de mot.</li> </ul>"},{"location":"lingualab-text-production/#fluence","title":"Fluence","text":""},{"location":"lingualab-text-production/#pauses-silencieuses","title":"Pauses silencieuses","text":"<p>Segments de l\u2019\u00e9chantillon au cours desquels aucun son n\u2019est produit apr\u00e8s que le participant ait commenc\u00e9 \u00e0 parler. C'est le nombre total de fois o\u00f9 \u00ab [pause] \u00bb appara\u00eet dans l\u2019\u00e9chantillon. Pourraient indiquer : difficult\u00e9s d\u2019acc\u00e8s lexical difficult\u00e9s syntaxiques difficult\u00e9s de planification du discours (Boschi et al. 2017).</p>"},{"location":"lingualab-text-production/#pauses-remplies","title":"Pauses remplies","text":"<p>Pause dans le discours marqu\u00e9e par \u00ab uhm \u00bb ou une variante de ce son (\u00ab hmmm \u00bb \u00ab hum \u00bb \u00ab er \u00bb \u00ab ah \u00bb etc.). Nombre total d\u2019occurrences des mots \u00ab uhm \u00bb \u00ab hmmm \u00bb \u00ab hum \u00bb \u00ab uh \u00bb \u00ab er \u00bb et \u00ab ah \u00bb dans l\u2019\u00e9chantillon. Pourraient indiquer : difficult\u00e9s d\u2019acc\u00e8s lexical difficult\u00e9s syntaxiques difficult\u00e9s de planification du discours (Boschi et al. 2017).</p>"},{"location":"lingualab-text-production/#repetitions-de-mots-de-groupes-de-mots-ou-didees","title":"R\u00e9p\u00e9titions de mots de groupes de mots ou d\u2019id\u00e9es","text":"<p>Mots ou informations de contenu qui sont pr\u00e9sentes plus d\u2019une fois dans l\u2019\u00e9chantillon (r\u00e9p\u00e9titions directement coll\u00e9es les unes sur les autres ou plus \u00e9loign\u00e9es dans l\u2019\u00e9chantillon). Nombre total de mots de groupes de mots (combinaisons de 2 \u00e0 6 mots) ou d\u2019informations de contenu qui sont pr\u00e9sents plus d\u2019une fois dans l\u2019\u00e9chantillon. Pourrait indiquer: d\u00e9ficits lexico- s\u00e9mantiques difficult\u00e9s de planification du discours (Boschi et al. 2017).</p>"},{"location":"lingualab-text-production/#noms-des-variables","title":"Noms des variables","text":"<ul> <li><code>Nombre_de_lemmes</code></li> <li><code>Nombre_de_fragments</code></li> <li><code>Nombre_de_fragments_autre_methode</code></li> <li><code>Fragments_en_contexte</code></li> <li><code>Nombre_de_mots</code></li> <li><code>Nombre_de_lemmes_differents</code></li> <li><code>Nombre_de_pauses_silencieuses</code></li> <li><code>Nombre_de_pauses_remplies</code></li> <li><code>Nombre_de_repetitions_mots</code></li> </ul>"},{"location":"lingualab-text-semantic/","title":"Caract\u00e9ristiques s\u00e9mantiques","text":""},{"location":"lingualab-text-semantic/#25-informations-de-contenu-icus","title":"25 informations de contenu (ICUs)","text":"<p>Sujets, lieux, objets et actions se\u0301pare\u0301s qui sont repre\u0301sente\u0301s dans l\u2019image Cookie Theft.</p> <p>La liste des unit\u00e9s de contenu (ICUs) pour le test de l'image du vol de cookies tel qu'\u00e9tabli par Yorkston et Beukelman (1980).</p> <p>La d\u00e9finition des ICUs se trouve ici</p>"},{"location":"lingualab-text-semantic/#nombre-total-dicus","title":"Nombre total d\u2019ICUs","text":"<p>Nombre total d\u2019ICUs qui apparaissent dans l\u2019e\u0301chantillon. Nombre total d\u2019ICUs e\u0301tiquete\u0301es comme \u00ab VRAI\u00bb.</p>"},{"location":"lingualab-text-semantic/#efficacite","title":"Efficacit\u00e9","text":"<p>Ratio de la longueur totale de l\u2019\u00e9chantillon sur le nombre total d\u2019ICUs pr\u00e9sentes dans l\u2019\u00e9chantillon.</p>"},{"location":"lingualab-text-semantic/#densite-didees","title":"Densit\u00e9 d\u2019id\u00e9es","text":"<p>Similarit\u00e9 s\u00e9mantique moyenne entre les id\u00e9es (conceptuellement distinctes) transmises \u00e0 l\u2019int\u00e9rieur d\u2019une fen\u00eatre de mots d\u00e9plac\u00e9e \u00e0-travers le texte.</p> <p>La distance cosine (similarit\u00e9 s\u00e9mantique) moyenne entre toutes les paires de \"word embeddings\" \u00e0 l\u2019int\u00e9rieur d\u2019une fen\u00eatre d\u00e9plac\u00e9e \u00e0-travers le texte. Les \"word embeddings\" seront extraits \u00e0 partir du mod\u00e8le spaCy <code>en_core_web_lg</code> qui a support\u00e9 l\u2019identification des d\u00e9pendances syntaxiques et le Part-of-Speech tagging. \u00c0 l\u2019int\u00e9rieur d\u2019une fen\u00eatre la moyenne de toutes les distances cosines sera calcul\u00e9e. Des fen\u00eatres de 3, 10, 25 et 40 mots avec un incr\u00e9ment de la moiti\u00e9 de la longueur de la fen\u00eatre seront impl\u00e9ment\u00e9es.</p>"},{"location":"lingualab-text-semantic/#noms-des-variables","title":"Noms des variables","text":"<ul> <li><code>Nombre_ICU_TRUE</code></li> <li><code>Efficacite_ICU</code></li> <li>TODO</li> </ul>"},{"location":"lingualab-text-syntaxic/","title":"Caract\u00e9ristiques syntaxiques","text":""},{"location":"lingualab-text-syntaxic/#dependances-syntaxiques-universelles","title":"D\u00e9pendances syntaxiques universelles","text":"<p>Les d\u00e9pendances syntaxiques universelles sont un ensemble de r\u00e8gles qui mod\u00e9lisent les relations grammaticales dans les langues. Elles se caract\u00e9risent par une structure hi\u00e9rarchique o\u00f9 les mots sont connect\u00e9s selon leur fonction syntaxique dans une phrase. Ces r\u00e8gles sont dites \"universelles\" car elles visent \u00e0 \u00eatre applicables \u00e0 travers diff\u00e9rentes langues offrant un cadre commun pour l'analyse linguistique.</p> <p>La relation de d\u00e9pendance directionnelle est une sp\u00e9cification de la grammaire de d\u00e9pendance qui \u00e9tablit une connexion entre une unit\u00e9 syntaxique (par exemple un verbe) et les entit\u00e9s qui composent sa structure relationnelle (comme les sujets et objets). Dans un arbre de d\u00e9pendance qui est une repr\u00e9sentation graphique de ces relations les mots ou morph\u00e8mes sont les n\u0153uds et les relations de d\u00e9pendance sont les ar\u00eates souvent annot\u00e9es par des fonctions syntaxiques telles que sujet objet etc.\u200b\u200b. https://fr.wikipedia.org/wiki/Grammaire_de_d\u00e9pendance </p> <p>Nombre total de chaque d\u00e9pendance syntaxique : Cela signifie compter combien de fois chaque type de relation de d\u00e9pendance (comme sujet, objet, compl\u00e9ment, etc.) appara\u00eet dans un texte.</p> <p>Calcul avec spaCy dependencies (DEP) : spaCy est capable d'analyser une phrase et d'identifier ces relations de d\u00e9pendance. Chaque mot dans une phrase est associ\u00e9 \u00e0 une \u00e9tiquette DEP qui d\u00e9crit son r\u00f4le syntaxique.</p> <p>Deux m\u00e9thodes de calcul : - En nombre absolu : Compter le nombre total de fois qu'une d\u00e9pendance syntaxique sp\u00e9cifique appara\u00eet. - En relation au nombre total de mots : Calculer la fr\u00e9quence de chaque d\u00e9pendance syntaxique par rapport au nombre total de mots dans l'\u00e9chantillon ce qui donne une mesure relative.</p>"},{"location":"lingualab-text-syntaxic/#exemple","title":"Exemple","text":"<p>Pour illustrer la relation de d\u00e9pendance directionnelle en syntaxe consid\u00e9rons la phrase simple : \"Le chat mange une souris.\"</p> <p>Dans un arbre de d\u00e9pendance pour cette phrase :</p> <ul> <li>\"mange\" serait la racine car c'est le verbe, l'action principale de la phrase.</li> <li>\"Le chat\" serait un actant, plus pr\u00e9cis\u00e9ment le sujet du verbe \"mange\". Il y aurait donc une fl\u00e8che directionnelle partant de \"mange\" et pointant vers \"chat\" indiquant que \"chat\" est le sujet de \"mange\".</li> <li>\"une souris\" serait un autre actant, l'objet direct du verbe \"mange\". De m\u00eame une fl\u00e8che directionnelle partirait de \"mange\" vers \"souris\" pour indiquer cette relation.</li> </ul> <p>Dans cet arbre chaque mot est connect\u00e9 par des lignes (ou ar\u00eates) qui montrent comment chaque mot d\u00e9pend du verbe (ou d'autres mots) pour sa fonction syntaxique dans la phrase.</p>"},{"location":"lingualab-text-syntaxic/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Universal Dependencies</li> <li>https://spacy.io/usage/linguistic-features#dependency-parse</li> </ul>"},{"location":"lingualab-text-syntaxic/#longueur-des-dependances-syntaxiques","title":"Longueur des d\u00e9pendances syntaxiques","text":"<p>Longueur moyenne et maximale des d\u00e9pendances syntaxiques. Nombre moyen et maximal de mots dans les d\u00e9pendances syntaxiques d\u2019un \u00e9chantillon.</p>"},{"location":"lingualab-text-syntaxic/#enfants-gauches-et-droits","title":"Enfants gauches et droits","text":"<p>D\u00e9pendants directs d\u2019un mot qui sont connect\u00e9s \u00e0 celui-ci par un seul arc \u00e0 sa gauche ou \u00e0 sa droite dans l\u2019arbre de d\u00e9pendance.</p> <p>On mesure le nombre moyen d'enfants gauches et droits pour chaque mot dans un \u00e9chantillon de textes. Cette mesure nous aide \u00e0 comprendre la structure syntaxique des phrases dans cet \u00e9chantillon.</p> <p>Calcul\u00e9 \u00e0 l\u2019aide des commandes spaCy <code>n_left</code> et <code>n_right</code> des deux fa\u00e7ons suivantes :</p> <ul> <li>en nombre absolu</li> <li>en relation au nombre total de mots dans l\u2019\u00e9chantillon</li> </ul> <p>https://spacy.io/usage/linguistic-features#navigating |</p>"},{"location":"lingualab-text-syntaxic/#verbes-avec-inflexions-verbes-conjugues","title":"Verbes avec inflexions (Verbes conjugu\u00e9s)","text":"<p>Verbes dans l\u2019\u00e9chantillon qui ne correspondent pas \u00e0 leur lemma tel qu\u2019extrait par spaCy.</p> <p>Calcul\u00e9 des deux fa\u00e7ons suivantes:</p> <ul> <li>en nombre absolu</li> <li>en relation au nombre total de mots dans l\u2019\u00e9chantillon</li> </ul>"},{"location":"lingualab-text-syntaxic/#clauses-subordonnees","title":"Clauses subordonn\u00e9es","text":"<p>Groupe de mots qui n\u2019exprime pas une pens\u00e9e compl\u00e8te, ne constitue pas une phrase compl\u00e8te. Les clauses complexes impliquant la subordination surviennent lorsqu\u2019un d\u00e9pendant syntaxique (principal ou non) est utilis\u00e9 comme structure causale.</p> <p>Nombre total des 4 types de d\u00e9pendances universelles de base calcul\u00e9 \u00e0 l\u2019aide du dependency parse par de\u0301faut de spaCy:</p> <ul> <li>Sujets clausaux (csubj)</li> <li>Comple\u0301ments clausaux divise\u0301s en ceux dont le sujet doit e\u0302tre contro\u0302le\u0301 (sujet a\u0300 l\u2019exte\u0301rieur de la clause; <code>xcomp</code>) et ceux dont le sujet n\u2019est pas contro\u0302le\u0301 (sujet a\u0300 l\u2019inte\u0301rieur de la clause; <code>ccomp</code>)</li> <li>Modificateurs de clauses adverbiaux (<code>advcl</code>)</li> <li>Modificateurs de clauses adnominaux (<code>acl</code>)</li> </ul> <p>Calcule\u0301 des deux fac\u0327ons suivantes :</p> <ul> <li>en nombre absolu </li> <li>en relation au nombre total de mots l\u2019e\u0301chantillon</li> </ul> <p>https://universaldependencies.org/u/overview/complex-syntax.html</p>"},{"location":"lingualab-text-syntaxic/#longueur-moyenne-des-phrases","title":"Longueur moyenne des phrases","text":"<p>Nombre moyen de mots par phrase. Le nombre moyen de mots par phrase dans l\u2019\u00e9chantillon sera calcul\u00e9. Les limites des phrases seront d\u00e9termin\u00e9es par le \"dependency parse\" par d\u00e9faut de spaCy.</p> <p>https://spacy.io/usage/linguistic-features#sbd</p>"},{"location":"lingualab-text-syntaxic/#phrases-incompletes","title":"Phrases incompl\u00e8tes","text":"<p>Phrases qui ne contiennent pas un minimum d\u2019un verbe et son sujet. Nombre total de phrases dans l\u2019\u00e9chantillon qui ne contiennent aucun verbe accompagn\u00e9 de son sujet.</p> <p>Calcule\u0301 des deux fac\u0327ons suivantes :</p> <ul> <li>en nombre absolu </li> <li>en relation au nombre total de mots l\u2019e\u0301chantillon</li> </ul> <p>Pourraient indiquer : d\u00e9ficits lexico-s\u00e9mantiques, d\u00e9ficits syntaxiques, difficult\u00e9s \u00e0 planifier le discours (Boschi et al. 2017).</p>"},{"location":"lingualab-text-syntaxic/#nombre-de-phrases-prepositionnelles","title":"Nombre de phrases pr\u00e9positionnelles","text":"<p>Phrases qui contiennent une pr\u00e9position son objet (nom ou pronom) et n\u2019importe quel modificateur de l\u2019objet, (Boschi et al. 2017).</p> <p>Calcule\u0301 des deux fac\u0327ons suivantes :</p> <ul> <li>en nombre absolu </li> <li>en relation au nombre total de mots l\u2019e\u0301chantillon</li> </ul>"},{"location":"lingualab-text-syntaxic/#nombre-de-phrases-verbales","title":"Nombre de phrases verbales","text":"<p>Phrases de bases contenant au moins un verbe et ces d\u00e9pendants. Calcule\u0301 a\u0300 l\u2019aide des imple\u0301mentations de base de spaCy.</p> <p>Calcule\u0301 des deux fac\u0327ons suivantes :</p> <ul> <li>en nombre absolu </li> <li>en relation au nombre total de mots l\u2019e\u0301chantillon</li> </ul>"},{"location":"lingualab-text-syntaxic/#longueur-et-nombre-de-phrases-nominales","title":"Longueur et nombre de phrases nominales","text":"<p>Une phrase nominale est un groupe de mots centr\u00e9 autour d'un nom (substantif) qui fonctionne comme sujet, objet ou compl\u00e9ment dans une phrase. Par exemple dans la phrase \"Le chat noir dort sur le tapis\", \"Le chat noir\" est une phrase nominale.</p> <p>La longueur d'une phrase nominale est le nombre de mots qui la composent. Elle peut varier de deux mots comme \"Une maison\" \u00e0 une s\u00e9quence plus longue comme \"La grande maison au bord de la route\".</p> <p>Nombre total et longueur moyenne des phrases nominales dans l\u2019\u00e9chantillon. Calcul\u00e9 \u00e0 l\u2019aide des impl\u00e9mentations de base de spaCy.</p> <p>Calcule\u0301 des deux fac\u0327ons suivantes:</p> <ul> <li>en nombre absolu </li> <li>en relation au nombre total de mots l\u2019e\u0301chantillon</li> </ul> <p>https://spacy.io/usage/linguistic-features#noun-chunks</p>"},{"location":"lingualab-text-syntaxic/#temps-de-verbes-utilises","title":"Temps de verbes utilis\u00e9s","text":"<p>Formes que prennent les verbes pour indiquer \u00e0 quel moment l\u2019action se situe dans le temps. Nombre total de verbes conjugu\u00e9s au pr\u00e9sent, au pass\u00e9 et au futur dans l\u2019\u00e9chantillon.</p> <p>Calcule\u0301 des deux fac\u0327ons suivantes:</p> <ul> <li>en nombre absolu </li> <li>en relation au nombre total de mots l\u2019e\u0301chantillon</li> </ul>"},{"location":"lingualab-text-syntaxic/#clauses-par-phrase","title":"Clauses par phrase","text":"<p>Groupes de mots comprenant un sujet et un verbe normalement utilis\u00e9s pour ajouter davantage de d\u00e9tails concernant un nom dans une phrase. Nombre moyen de clauses par phrase calcul\u00e9 \u00e0 l\u2019aide des impl\u00e9mentations de base de spaCy.</p>"},{"location":"lingualab-text-syntaxic/#proportion-de-noms-accompagnes-de-determinants","title":"Proportion de noms accompagn\u00e9s de d\u00e9terminants","text":"<p>Proportion de noms pour lesquels un d\u00e9terminant est pr\u00e9sent. Nombre de noms dans l\u2019\u00e9chantillon rattach\u00e9s \u00e0 un d\u00e9terminant sur le nombre total de noms dans l\u2019\u00e9chantillon. Calcul\u00e9 \u00e0 l\u2019aide du dependency parse de spaCy.</p>"},{"location":"lingualab-text-syntaxic/#phrases-coordonnees","title":"Phrases coordonn\u00e9es","text":"<p>Phrases unies par une ou plusieurs conjonctions de coordination. Nombre total de phrases dans l\u2019\u00e9chantillon contenant les conjonctions de coordination suivantes: \"and\", \"but\", \"for\", \"nor\", \"or\", \"yet\", \"so\" (Boschi et al. 2017).</p> <p>Calcule\u0301 des deux fac\u0327ons suivantes:</p> <ul> <li>en nombre absolu </li> <li>en relation au nombre total de mots l\u2019e\u0301chantillon</li> </ul>"},{"location":"lingualab-text-syntaxic/#noms-des-variables","title":"Noms des variables","text":"<ul> <li><code>Longueur_moyenne_des_dependances</code></li> <li><code>Longueur_maximale_des_dependances</code></li> <li><code>Moyenne_enfants_gauches</code></li> <li><code>Moyenne_enfants_droits</code></li> <li><code>Total_enfants_gauches</code></li> <li><code>Total_enfants_droits</code></li> <li><code>Nombre_de_verbes_inflexion</code></li> <li><code>Verbe_inflection_relatif</code></li> <li><code>Sujets_Clausaux_absolu</code></li> <li><code>Sujets_Clausaux_relatif</code></li> <li><code>Complements_Clausaux_Controles_absolu</code></li> <li><code>Complements_Clausaux_Controles_relatif</code></li> <li><code>Complements_Clausaux_Non_Controles_absolu</code></li> <li><code>Complements_Clausaux_Non_Controles_relatif</code></li> <li><code>Modificateurs_Clauses_Adverbiaux_absolu</code></li> <li><code>Modificateurs_Clauses_Adverbiaux_relatif</code></li> <li><code>Modificateurs_Clauses_Adnominaux_absolu</code></li> <li><code>Modificateurs_Clauses_Adnominaux_relatif</code></li> <li><code>Longueur_moyenne_phrases</code></li> <li><code>Nombre_de_phrases_incompletes_absolu</code></li> <li><code>Nombre_de_phrases_incompletes_relatif</code></li> <li><code>Nombre_de_phrases_prepositionnelles_absolu</code></li> <li><code>Nombre_de_phrases_prepositionnelles_relatif</code></li> <li><code>Nombre_de_phrases_verbales_absolu</code></li> <li><code>Nombre_de_phrases_verbales_relatif</code></li> <li><code>Nombre_absolu_phrases_nominales</code></li> <li><code>Longueur_moyenne_phrases_nominales</code></li> <li><code>Frequence_relative_phrases_nominales</code></li> <li><code>Nbre_verb_present_absolu</code></li> <li><code>Nbre_verb_present_relatif</code></li> <li><code>Nbre_verb_past_absolu</code></li> <li><code>Nbre_verb_past_relatif</code></li> <li><code>Nbre_verb_future_absolu</code></li> <li><code>Nbre_verb_future_relatif</code></li> <li><code>Nbre_clauses_par_phrase</code></li> <li><code>Proportion_noms_determinants</code></li> <li><code>Nombre_de_phrases_coordonnees</code></li> <li><code>Frequence_relative_phrases_coordonnees</code></li> </ul>"},{"location":"en/lingualab-audio-phonetics/","title":"Extraction of phonetic variables","text":""},{"location":"en/lingualab-audio-phonetics/#variable-definition","title":"Variable definition","text":"Characteristic/feature family Definition Fundamental Frequency (F0) Variations in voice pitch, useful for analyzing intonation and emotional stress. Intensity (Volume) Measure of loudness, can reflect emphasis or emotional changes. Voice Quality Characteristics such as roughness, breathiness, clarity or nasality of the voice. Spectrogram Visual representation of frequency evolution over time, useful for detailed analysis of sound characteristics. Formant Frequencies (F1, F2, etc.) Important information on the characteristics of pronounced vowels. Frequency and Amplitude Modulation Variations in frequency and amplitude within the same phoneme or word. Harmonic-to-Noise Ratio (HNR) Ratio between harmonic and noisy components of the voice, useful for assessing vocal quality. Jitter (Frequency Variability) Variability in the fundamental frequency of a sound, can indicate vocal stress or tension. Shimmer (Amplitude Variability) Variability in the amplitude of sound waves, related to vocal stability and quality. Phonation These characteristics focus on aspects of vocal production linked to vocal cord activity. They include measures such as pitch, jitter and shimmer, which are indicators of the frequency and amplitude stability of the voice. Articulation These characteristics relate to the way words and sounds are formed by the speaker. They can include measures of phoneme duration, articulation speed and articulatory movement dynamics. Prosody Prosody concerns the rhythm, intonation and accentuation of speech. Prosodic features include measures of intensity, syllable duration and stress patterns. Phonology These characteristics analyze aspects of speech related to phonemic structure, such as changes in vowel or consonant quality. <p>Praat, PyDub, librosa</p> <p>https://github.com/jcvasquezc/DisVoice</p>"},{"location":"en/lingualab-audio-phonetics/#variable-names","title":"Variable names","text":"<ul> <li><code>F0_std</code></li> <li><code>duration</code></li> <li><code>f0_mean</code></li> <li><code>formants_1_mean</code></li> <li><code>formants_1_median</code></li> <li><code>formants_2_mean</code></li> <li><code>formants_2_median</code></li> <li><code>formants_3_mean</code></li> <li><code>formants_3_median</code></li> <li><code>formants_4_mean</code></li> <li><code>formants_4_median</code></li> <li><code>hnr</code></li> <li><code>jitter_ddp</code></li> <li><code>jitter_local</code></li> <li><code>jitter_local_absolute</code></li> <li><code>jitter_ppq5</code></li> <li><code>jitter_rap</code></li> <li><code>shimmer_apq11</code></li> <li><code>shimmer_apq3</code></li> <li><code>shimmer_apq5</code></li> <li><code>shimmer_dda</code></li> <li><code>shimmer_local</code></li> <li><code>shimmer_local_dB</code></li> </ul>"},{"location":"en/lingualab-text-lexical/","title":"Lexical features","text":""},{"location":"en/lingualab-text-lexical/#parts-of-speech","title":"Parts-of-Speech","text":"<p>Grammatical class of a word. Parts-of-Speech (POS) categorization refers to the classification of words according to their grammatical function in a sentence. This includes determining the class to which each word belongs, such as nouns pronouns verbs adverbs adjectives prepositions determiners and conjunctions.</p> <p>Number of occurrences of each grammatical class (nouns pronouns verbs adverbs adjectives prepositions determiners conjunctions) in the sample. Calculated in 2 ways: as an absolute number and in relation to the total number of words in the sample.</p>"},{"location":"en/lingualab-text-lexical/#open-and-closed-class-words","title":"Open and closed class words","text":"<p>Open-class words\" and \"closed-class words\" are two main categories in the classification of words according to their role in the language. Total number of open-class words (nouns verbs adjectives adverbs) and closed-class words (conjunctions pronouns determiners prepositions) in the sample.</p>"},{"location":"en/lingualab-text-lexical/#open-class-words","title":"Open Class Words","text":"<p>These words are the main content of the speech. They are called \"open\" because new words can be regularly added to these categories.</p> <p>These words include :</p> <ul> <li>Nouns: Represent people places objects ideas (e.g. apple freedom).</li> <li>Verbs: Designate actions, states and occurrences (e.g.: run, be).</li> <li>Adjectives: Qualify or quantify nouns (e.g.: fast big).</li> <li>Adverbs: Modify verbs, adjectives or other adverbs (e.g.: quickly very).</li> </ul>"},{"location":"en/lingualab-text-lexical/#closed-class-words","title":"Closed Class Words","text":"<p>These words have a grammatical function rather than conveying concrete content. They form a relatively fixed and limited set of terms.</p> <p>These words include : - Conjunctions: connect words with phrases or clauses (e.g. and but). - Pronouns: Replace nouns (e.g.: she the one). - Determiners: Specify nouns (e.g.: the one). - Prepositions: Link a noun to another element of the sentence (e.g. in on).</p>"},{"location":"en/lingualab-text-lexical/#example","title":"Example","text":"<p>Here are the general steps for counting words in open and closed classes in Python using NLTK :</p> <ul> <li>Download Necessary Resources: Use <code>nltk.download('punkt')</code> and <code>nltk.download('averaged_perceptron_tagger')</code>.</li> <li>Tokenize text and apply POS tagging: Use word_tokenize to divide text into words and pos_tag to apply POS tagging to each word.</li> <li>Word Count: Count occurrences of words belonging to open (nouns verbs adjectives adverbs) and closed (conjunctions pronouns determiners prepositions) classes and calculate these numbers in absolute terms.</li> </ul>"},{"location":"en/lingualab-text-lexical/#ratio-of-different-parts-of-speech-and-word-types","title":"Ratio of different Parts-of-Speech and word types","text":"<p>Ratio of words of different grammatical classes or word types to the total number of words in the sample or to the total number of words of one or more other grammatical class(es). </p> <p>Total number of occurrences of a grammatical class in the sample divided by the total number of words in the sample or by the number of occurrences of one or more other grammatical class(es).</p> <p>The following ratios will be calculated: </p> <ul> <li>Pronouns/Nouns + Pronouns </li> <li>Nouns/Noms + Pronouns </li> <li>Nouns/Noms + Verbs</li> <li>Verbs/Nouns + Verbs</li> <li>Verbs with inflections/Total number of verbs</li> <li>Number of open class words/Total number of words</li> <li>Number of closed words/Total number of words</li> <li>Gerunds/Total number of verbs</li> <li>Gerunds/Total number of words</li> </ul>"},{"location":"en/lingualab-text-lexical/#light-verbs","title":"Light verbs","text":"<p>A light verb is a linguistic term for a verb that, taken on its own, has a limited or generic semantic content, but when combined with other words (such as nouns, adjectives or prepositions) helps create a verbal expression with a richer or more specific meaning. These often common and versatile verbs like \"to do\" \"to put\" \"to take\" acquire a more nuanced and specific meaning in the context of their combination with other linguistic elements. </p> <p>Number of occurrences of the following verbs (infinitive or conjugated) in the sample: be, have, come, go, give, take, make, do, get, move, put.</p> <p>Calculated in two ways: - in absolute numbers - in relation to the total number of verbs in the sample</p>"},{"location":"en/lingualab-text-lexical/#deictic-pronouns","title":"Deictic pronouns","text":"<p>Pronouns used to refer directly to personal temporal or local characteristics of the image to be described. The specific meaning of these pronouns depends on the context in which they are used (Crystal 2011).</p> <p>Total number of occurrences of words in the following four categories in the sample:</p> <ul> <li>Spatial deixis: this, that, here, there.</li> <li>Personal deixis: he, she, her, herself, him, himself.</li> <li>Temporal deixis: then, now, soon, recently.</li> <li>Deictic pronouns: sum of deictic pronouns from the three preceding categories.</li> </ul> <p>Calculated in 2 ways: - in absolute number - in relation to the total number of words in the sample</p>"},{"location":"en/lingualab-text-lexical/#indefinite-terms","title":"Indefinite terms","text":"<p>In a linguistic context, \"indefinite terms\" are words used to refer to objects, people or quantities in a vague or non-specific way, without designating a precise element. They are often used to talk about things in a general way or to indicate an indeterminate quantity.</p> <p>Examples:</p> <ul> <li>General objects or things: thing, stuff.</li> <li>Quantitative indefinites: little, much, few, many, several.</li> <li>Person indefinites: anyone, everyone, no one, someone, everybody, nobody.</li> <li> <p>Other Indefinites: another, the other, each, either, neither, both, other, others.</p> </li> <li> <p>General objects or things: thing, thing.</p> </li> <li>Quantitative Indefinites: little, much, some, many.</li> <li>Person indefinites: someone, everyone, nobody, everyone, anyone.</li> <li>Other Indefinites: other, the other, each, neither, both, others.</li> </ul> <p>Total number of occurrences of the following terms in the sample, calculated in 2 ways:</p> <ul> <li>as an absolute number</li> <li>in relation to the total number of words in the sample</li> </ul>"},{"location":"en/lingualab-text-lexical/#moving-average-type-token-ratio-mattr","title":"Moving Average Type-Token Ratio (MATTR)","text":"<p>The Moving-Average Type-Token Ratio (MATTR) is a linguistic measure that calculates the moving average for all segments of a given length in a text. For a 50-word segment, for example, the Type-Token Ratio (TTR) is calculated for words 1-50 2-51 3-52 etc., and the resulting TTR measurements are averaged to produce the final MATTR value. This approach provides a more stable and representative measure of the lexical diversity of a text, as it minimizes the impact of text length on TTR.</p> <p>Calculated by moving a window of size <code>x</code> across the text. For each window, a Type-Token Ratio is obtained by dividing the number of unique words by the total number of words in the window. To obtain the overall MATTR of a sample, the TTR of each window is averaged. The length of each window is determined by calculating the average number of words in all DS samples.</p> <p>Three window groups will therefore be obtained so that each window contains 10 25 and 40 words (Covington &amp; McFall 2010).</p> <p>A higher MATTR indicates greater lexical diversity (Covington &amp; McFall 2010).</p> <p>https://pypi.org/project/taaled/#:~:text=The Moving15</p>"},{"location":"en/lingualab-text-lexical/#honores-r-statistic","title":"Honor\u00e9's R statistic","text":"<p>Honor\u00e9's R statistic is a measure of lexical diversity that takes into account sample length, the number of different words used and the number of words mentioned only once.</p> <p>It is calculated according to the formula: <code>R=100\u00d7log(N)/(1-(V1/V))</code>.</p> <ul> <li>N is the total number of words in the sample.</li> <li>V is the number of different words in the sample.</li> <li>V1 is the number of words mentioned only once.</li> </ul> <p>This measure is particularly useful for analyzing longer texts, as it reduces the sensitivity of the lexical diversity measure to text length.</p> <p>A higher Honor\u00e9 statistic indicates greater lexical diversity.</p> <p>To operationalize and calculate the Honor\u00e9 R statistic in Python you first need to tokenize your text to obtain the total number of words (N) count the number of unique words (V) and identify those that appear only once (V1). Then you can apply the above formula to obtain the value of R.</p>"},{"location":"en/lingualab-text-lexical/#brunets-w-index","title":"Brunet's W index","text":"<p>A measure of lexical diversity relating sample length to the number of different words used in the sample.</p> <p>The formula for this index is: <code>W = N ^ (V ^ (-0.165))</code></p> <ul> <li>W is Brunet's W index.</li> <li>N is the total number of words in the text (also known as the token count).</li> <li>V is the total number of unique words (also known as the type count).</li> </ul> <p>A higher Brunet W index indicates less lexical diversity (inverted scale). Relatively unaffected by variations in sample length.</p>"},{"location":"en/lingualab-text-lexical/#familiarity","title":"Familiarity","text":"<p>Degree to which a word is familiar to speakers of a language. Subjective familiarity ratings obtained from Glasgow norms (Scott et al. 2019).</p> <p>Average familiarity will be calculated for all: words, nouns, verbs and adjectives in the sample.</p> <p>Semantic and/or lexical access deficits could be manifested by increased use of words rated as highly familiar (Fraser et al. 2016).</p>"},{"location":"en/lingualab-text-lexical/#imageability","title":"Imageability","text":"<p>Level of effort involved in generating a mental image of the concept represented by a word. Subjective ratings of imageability obtained from Glasgow norms (Scott et al. 2019).</p> <p>Average imageability will be calculated for all: words, nouns, verbs and adjectives in the sample.</p> <p>The \"Glasgow Norms\" are a set of normative ratings for 5,553 English words evaluated on nine psycholinguistic dimensions: arousal, valence, dominance, concreteness, imageability, familiarity, age of acquisition, semantic size, and gender association. This corpus is unique in several respects. It is relatively large and provides norms on a large number of lexical dimensions. For each subset of words, the same participants provided ratings on all nine dimensions. In addition, the corpus contains a set of 379 ambiguous words presented alone or with information selecting another meaning. The relationships between the Glasgow Norms dimensions were initially investigated by assessing their correlations. Principal component analysis revealed four main factors accounting for 82% of the variance. The validity of the Glasgow Norms was established through comparisons with 18 different sets of current psycholinguistic norms. The Glasgow Norms offer a valuable resource particularly for researchers investigating the role of word recognition in language comprehension.</p> <p>https://pubmed.ncbi.nlm.nih.gov/30206797/</p>"},{"location":"en/lingualab-text-lexical/#concreteness","title":"Concreteness","text":"<p>Degree to which the concept denoted by a word refers to a perceptible/tangible entity. Subjective assessments of concreteness from Brysbaert et al. 2014.</p> <p>Average concreteness will be calculated for all: words, nouns, verbs and adjectives in the sample.</p> <p>Concreteness ratings are presented for 37,058 English words and 2,896 two-word phrases (such as crosswalk and zoom in) obtained from over 4,000 participants through a standardization study using Internet crowdsourcing for data collection.\u00a0Although the instructions stress that the assessment of word concreteness would be based on experiences involving all senses and motor responses a comparison with existing concreteness norms indicates that participants as before focused largely on visual and haptic experiences.\u00a0The reported dataset is a subset of a complete list of English lemmas and contains all lemmas known to at least 85% of raters.\u00a0It can be used in future research as a reference list of generally known English lemmas.</p> <p>https://pubmed.ncbi.nlm.nih.gov/24142837/</p>"},{"location":"en/lingualab-text-lexical/#word-frequency-in-everyday-language","title":"Word frequency in everyday language","text":"<p>Evaluation of the frequency with which a word is used in everyday speech by speakers of a language. Objective measurement of word frequency from the SUBTLEX-US corpus (Brysbaert &amp; New 2009).</p> <p>The average frequency will be calculated for all: words, nouns, verbs and adjectives in the sample.</p> <p>The SUBTLEX-US database contains word frequencies based on film subtitles as developed by Brysbaert and New in 2009. This database offers an objective measure of word frequency in American English drawn from a large corpus of subtitles. It also includes information on parts of speech (PoS) and uses Zipf's word frequency scale. This approach provides more representative data on word usage in everyday spoken language than frequencies based on written or literary texts. It is therefore particularly useful for research in psycholinguistics and automatic language processing.</p> <p>Difficulties in accessing specific words generally result in the overuse of words with a high frequency (Wang et al. 2021). https://osf.io/djpqz/</p>"},{"location":"en/lingualab-text-lexical/#valence","title":"Valence","text":"<p>Degree of agreeableness of emotions invoked by a word. Subjective valence assessments from Warriner et al. 2013.</p> <p>Average valence will be calculated for all: words, nouns, verbs and adjectives in the sample.</p> <p>The 2013 Warriner et al. study involved subjective valence ratings of arousal and dominance for 13,915 English lemmas. This research involved a group of 1,827 participants rating the emotional valence of these words in an online scoring study, https://www.frontiersin.org/journals/communication/articles/10.3389/fcomm.2021.770497/full.</p> <p>Valence in this context refers to the affective quality of a word indicating whether it evokes positive or negative feelings. The researchers found a strong correlation between valence and dominance suggesting that stimuli could not easily be identified as varying in valence while remaining constant in dominance, https://www.sciencedirect.com/science/article/pii/S0001691821001098. The results showed that the mean standard deviation of valence ratings was 168 while that of arousal ratings for the same words was 230 indicating greater variability in arousal than valence ratings, https://www.sciencedirect.com/science/article/pii/S0346251X19302039.</p> <p>These norms of arousal valence and dominance for English words are used by researchers working on emotions and moods word recognition and memory as well as text-based sentiment analysis, https://pubmed.ncbi.nlm.nih.gov/23404613/. Warriner et al.'s research thus makes a significant contribution to our understanding of how words are emotionally perceived and their impact on various areas of psycholinguistics.</p>"},{"location":"en/lingualab-text-lexical/#french-databases","title":"French databases","text":"<p>Here are the databases for the French language: Open Lexicon FR, Les bases de donn\u00e9es lexicales en fran\u00e7ais</p>"},{"location":"en/lingualab-text-lexical/#variable-names","title":"Variable names","text":"<ul> <li><code>Mots_de_classe_ouverte</code></li> <li><code>Mots_de_classe_fermee</code></li> <li><code>Nombre_de_gerondifs</code></li> <li><code>Pronoms/(Noms+Pronoms)</code></li> <li><code>Noms/(Noms+Pronoms)</code></li> <li><code>Noms/(Noms+Verbes)</code></li> <li><code>Verbes/(Noms+Verbes)</code></li> <li><code>Verbes_avec_inflexions/Total_Verbes</code></li> <li><code>Mots_de_classe_ouverte/Total_Mots</code></li> <li><code>Mots_de_classe_fermee/Total_Mots</code></li> <li><code>Gerondifs/Total_Verbes</code></li> <li><code>Gerondifs/Total_Mots</code></li> <li><code>Nombre_de_pronoms_deictiques</code></li> <li><code>Nombre_de_pronoms_deictiques_spatiaux</code></li> <li><code>Nombre_de_pronoms_deictiques_personnels</code></li> <li><code>Nombre_de_pronoms_deictiques_temporels</code></li> <li><code>Nombre_de_termes_indefinis</code></li> <li><code>Ratio_termes_indefinis</code></li> <li><code>MATTR_10</code></li> <li><code>MATTR_25</code></li> <li><code>MATTR_40</code></li> <li><code>Nombre_de_mots_uniques</code></li> <li><code>Statistique_R_de_Honore</code></li> <li><code>Familiarite_moyenne_mots</code></li> <li><code>Familiarite_moyenne_noms</code></li> <li><code>Familiarite_moyenne_verbes</code></li> <li><code>Familiarite_moyenne_adjectifs</code></li> <li><code>Imageabilite_moyenne_mots</code></li> <li><code>Imageabilite_moyenne_noms</code></li> <li><code>Imageabilite_moyenne_verbes</code></li> <li><code>Imageabilite_moyenne_adjectifs</code></li> <li><code>Concretude_moyenne_mots</code></li> <li><code>Concretude_moyenne_noms</code></li> <li><code>Concretude_moyenne_verbes</code></li> <li><code>Concretude_moyenne_adjectifs</code></li> <li><code>Frequence_moyenne_mots</code></li> <li><code>Frequence_moyenne_noms</code></li> <li><code>Frequence_moyenne_verbes</code></li> <li><code>Frequence_moyenne_adjectifs</code></li> <li><code>Valence_moyenne_mots</code></li> <li><code>Valence_moyenne_noms</code></li> <li><code>Valence_moyenne_verbes</code></li> <li><code>Valence_moyenne_adjectifs</code></li> <li><code>Brunet_W_indice</code></li> </ul>"},{"location":"en/lingualab-text-pragmatic/","title":"Pragmatic features","text":""},{"location":"en/lingualab-text-pragmatic/#local-consistency","title":"Local consistency","text":"<p>Semantic similarity between a sentence and its predecessor.</p> <p>The average semantic similarity score, often calculated by the cosine distance, is a common measure in automatic language processing (NLP) for evaluating the semantic proximity between sentences.</p> <p>Cosine distance is a measure of similarity between two vectors in a multidimensional space, calculated by measuring the cosine of the angle between them. In NLP, this measure is often used to compare vectors of words or phrases, where the vectors represent the semantic distribution of terms. The <code>cosine_similarity</code> function in the scikit-learn library is an implementation of this measure.</p> <p>Higher values indicate greater similarity and less semantic distance. Lower values indicate less similarity and greater semantic distance.</p>"},{"location":"en/lingualab-text-pragmatic/#words-denoting-uncertainty","title":"Words denoting uncertainty","text":"<p>Words denoting uncertainty about the nature of an image element to be described.</p> <p>Number of occurrences of the following words in the sample: \"think\", \"look\", \"like\", \"kind\", \"seem\", \"maybe\", \"can\", \"something\".</p> <p>Calculated in two ways:</p> <ul> <li>in absolute numbers </li> <li>in relation to the total number of words in the sample</li> </ul> <p>Word list inspired by (Garrard et al., 2014), It is necessary to make a French version.</p>"},{"location":"en/lingualab-text-pragmatic/#difficulty-finding-the-right-words","title":"Difficulty finding the right words","text":"<p>Use of words indicating lexical access difficulties.</p> <p>Number of instances of the following words in the sample: \"know\", \"remember\", \"unable\".</p> <p>Calculated in two ways:</p> <ul> <li>absolute number </li> <li>in relation to the total number of words in the sample</li> </ul> <p>Word list inspired by (Garrard et al., 2014) and (Rentoumi et al., 2014), It is necessary to make a French version.</p>"},{"location":"en/lingualab-text-pragmatic/#connotation-of-speech","title":"Connotation of speech","text":"<p>Emotions generated by speech. Depends on the average valence of the words in the speech. The average valence score of all the words in the sample will be obtained when the psycholinguistic variables are extracted. For each word, possible scores range from 1 to 9. A higher score indicates that a word has a more positive connotation, while a lower score indicates a more negative connotation. </p> <ul> <li>If the average valence is greater than or equal to 5, the label \"positive connotation\" will be given to the speech.</li> <li>If the average valence is greater than or equal to 4 and less than 5, the label \"neutral connotation\" will be given to the speech.</li> <li>If the average valence is less than 4, the label \"negative connotation\" will be given to the speech.</li> </ul>"},{"location":"en/lingualab-text-pragmatic/#formulaic-expressions","title":"Formulaic expressions","text":"<p>Expressions with a fixed form and non-literal meaning with attitudinal nuances.</p> <p>Total number of occurrences of the following formulaic expressions in the sample: \"well\", \"so\", \"I guess\", \"you know\", \"as it is\", \"as it were\". (Van Lancker Sidtis et al. 2015)</p> <p>Calculated in the following two ways: </p> <ul> <li>in absolute numbers </li> <li>in relation to the total number of words in the sample</li> </ul>"},{"location":"en/lingualab-text-pragmatic/#modalizations","title":"Modalizations","text":"<p>An individual's opinions about the content of his or her description (or what is happening on the image to be described), including doubts and concerns about his or her production.</p> <p>Total number of occurrences of the following expressions in the sample: \"I think\", \"In my opinion\", \"of course\", \"naturally\", \"unsure\", \"likely\", \"could be that\", \"unfortunately\", \"surely\". (Boschi et al. 2017, Boy\u00e9 et al. 2014)</p> <p>Calculated in the following two ways: </p> <ul> <li>in absolute numbers </li> <li>in relation to the total number of words in the sample</li> </ul>"},{"location":"en/lingualab-text-pragmatic/#filler-words","title":"Filler words","text":"<p>Words or groups of words used to emphasize what will be said or has been said, or which indicate that an individual is thinking about what to say next.</p> <p>Total number of times the expressions \"you know\", \"I mean\" are mentioned in the sample.</p> <p>Calculated in two ways: </p> <ul> <li>in absolute numbers </li> <li>in relation to the total number of words in the sample</li> </ul> <p>Could give information on an individual's lexical access capacity.</p> <p>Note: This table is a modified version of the one found in Slegers et al. 2021 and Pellerin Sophie.</p>"},{"location":"en/lingualab-text-pragmatic/#variable-names","title":"Variable names","text":"<ul> <li><code>Coherence_locale</code></li> <li><code>Sentiment-valence</code></li> <li><code>Emotion</code></li> <li><code>Nombre_de_mots_incertitude</code></li> <li><code>Frequence_relative_mots_incertitude</code></li> <li><code>Nombre_de_mots_difficulte_acces_lexical</code></li> <li><code>Frequence_relative_mots_difficulte_acces_lexical</code></li> <li><code>Nombre_de_mots_expression_formulaiques</code></li> <li><code>Frequence_relative_mots_expression_formulaiques</code></li> <li><code>Nombre_de_mots_modalisations</code></li> <li><code>Frequence_relative_mots_modalisations</code></li> <li><code>Nombre_de_mots_de_remplissage</code></li> <li><code>Frequence_relative_mots_de_remplissage</code></li> </ul>"},{"location":"en/lingualab-text-production/","title":"Speech production","text":""},{"location":"en/lingualab-text-production/#definitions","title":"Definitions","text":""},{"location":"en/lingualab-text-production/#lemmatization","title":"Lemmatization","text":"<p>A lemma in the context of linguistics is the basic or reference canonical form of a word. In other words, it's the form in which a word is listed in a dictionary or used to represent all the inflectional variants of a word. The idea is to group together the different forms of a word (such as future past tenses, plurals etc.) in a single standardized form.</p> <p>Lemmas are not punctuation markers or filled pauses (such as \"hmm\" or \"uh\"), which are usually omitted in lexical analysis because they carry no specific lexical meaning.</p> <p>Examples:</p> <ul> <li>\"dog\", \"dogs\" is \"dog\".</li> <li> <p>\"best\", \"better\" is \"good\"</p> </li> <li> <p>Process: Lemmatization involves a complete morphological analysis of words to deduce their canonical form or lemma. Lemmatization takes into account the context of the word, its gender, number and tense, to determine its basic form.</p> </li> <li>Example: Taking your example, the word \"find\" is reduced to its basic form \"find\". Unlike stemming, the result of lemmatization is always a valid, recognizable word.</li> <li>Usage: Lemmatization is often used in situations where precision is crucial, such as in natural language understanding systems or linguistic applications where context understanding and semantic precision are important.</li> </ul>"},{"location":"en/lingualab-text-production/#phoneme","title":"Phoneme","text":"<p>A phoneme is a basic unit of sound in a language that distinguishes one word from another. It is the smallest unit of sound that can change the meaning of a word. Phonemes are abstract concepts used to analyze how sounds function in a particular language. They are not the sounds themselves, but rather categories of sounds that can be pronounced in different ways by different speakers, yet still be perceived as the same sound.</p> <p>In French, the sounds /p/ and /b/ are distinct phonemes, differentiating words like \"patte\" and \"batte\". The phoneme /k/ is present in the words \"caf\u00e9\" and \"quai\", although the sound is produced differently in each word (with a different letter).</p> <p>In English, the /t/ and /d/ phonemes differentiate the words \"tap\" and \"dap\" (a made-up word that sounds different thanks to the different initial phoneme).</p>"},{"location":"en/lingualab-text-production/#tokenization","title":"Tokenization","text":"<p>Breakdown of text into several parts called tokens.</p> <p>Example: \"You will find the document in question attached\" gives \"You\", \"will find\", \"in\", \"part\", \"attached\", \"the\", \"document\", \"in\", \"question\".</p>"},{"location":"en/lingualab-text-production/#stemming","title":"Stemming","text":"<ol> <li>Process: Stemming consists in cutting off the ends (suffixes and sometimes prefixes) of words to achieve a simplified form. This process is generally heuristic, and takes no account of the context or complete morphology of words. It is based on simple, fixed rules for truncating words.</li> <li>Example: In your example, \"trouverez\" becomes \"trouv\". Here the suffix \"-erez\" is removed to arrive at the root \"trouv\". This root is not necessarily a valid word in itself.</li> <li>Usage: Stemming is often used in search and filter systems where precision is not critical, but speed and simplicity of the process are important.</li> </ol>"},{"location":"en/lingualab-text-production/#lemmatization_1","title":"Lemmatization","text":"<p>This involves performing the same task as stemming, but using a vocabulary and a fine-grained analysis of word construction. Lemmatization removes only inflexible endings and thus isolates the canonical form of the word** known as the lemma.</p>"},{"location":"en/lingualab-text-production/#semantic-similarity","title":"Semantic similarity","text":"<p>Semantic similarity measures how close two words or concepts are in meaning. In the context of word embeddings, this is often expressed by the proximity of their vectors in vector space.</p>"},{"location":"en/lingualab-text-production/#word-embedding","title":"Word Embedding","text":"<p>Word Embedding is an encoding method that aims to represent the words or phrases of a text by vectors of real numbers described in a Vector Space Model.</p> <p>In simple terms, each word of the vocabulary V under study will be represented by a vector of size m. The principle of Word Embedding is to project each of these words into a vector space of fixed size N (N being different from m). In other words, whatever the size of the vocabulary, we need to be able to project a word into its own space.</p>"},{"location":"en/lingualab-text-production/#embedding-templates","title":"Embedding templates","text":"<p>CBOW (Continuous Bag-of-Words): In this model, the target word is predicted from surrounding words. It takes into account the context represented by neighboring words to predict the target word.</p> <p>Skip-Gram: Inverse of CBOW, this model predicts the context of a given word. It is effective for representing rare words or phrases.</p>"},{"location":"en/lingualab-text-production/#dependency-tree","title":"Dependency tree","text":"<p>In a dependency grammar, a sentence is represented as a tree. Each word in the sentence is a node in this tree. The links (or arcs) between these words represent syntactic relationships.</p>"},{"location":"en/lingualab-text-production/#variables","title":"Variables","text":""},{"location":"en/lingualab-text-production/#sample-length","title":"Sample length","text":"<p>Total number of words in the sample. This is the total number of lemmas that are not punctuation markers, including filled pauses (e.g. hmmm).</p>"},{"location":"en/lingualab-text-production/#word-fragments","title":"Word fragments","text":"<p>Production of only part of a word's phonemes without sound replacements or articulation errors. May or may not be followed by full word production. A word fragment is a portion of a word that contains one or more phonemes of that word, but not all its phonemes. In other words, it's a part of a word, not the complete word.</p> <ul> <li>Fragments Identification**: In the speech or text sample you are looking for occurrences where only part of a word is spoken or written. This can be the beginning of a word, the end or even the middle, as long as it's not the whole word.</li> <li>Fragments Count**: You then count the total number of these fragments in the sample. Each occurrence of a word fragment is counted as a separate unit.</li> <li>Exclude Pronunciation Errors and Sound Substitutions**: It's important to note that word fragments should not be confused with pronunciation errors or sound substitutions. These are specific occurrences where missing phonemes are not replaced by other sounds or errors.</li> <li>Example : \"I her kitchkitchen\" An example of this would be in a speech sample where someone starts to say a word but stops before finishing it like starting to say \"incomprehens...\" instead of \"incomprehensible\". Each time this happens it would count as a word fragment.</li> </ul>"},{"location":"en/lingualab-text-production/#fluency","title":"Fluency","text":""},{"location":"en/lingualab-text-production/#silent-pauses","title":"Silent pauses","text":"<p>Segments of the sample in which no sound is produced after the participant has started speaking. This is the total number of times \"[pause]\" appears in the sample. Could indicate: lexical access difficulties syntactic difficulties speech planning difficulties (Boschi et al. 2017).</p>"},{"location":"en/lingualab-text-production/#filled-pauses","title":"Filled pauses","text":"<p>Pause in speech marked by \"uhm\" or a variant of this sound (\"hmmm\" \"hum\" \"er\" \"ah\" etc.). Total number of occurrences of the words \"uhm\" \"hmmm\" \"hum\" \"uh\" \"er\" and \"ah\" in the sample. Could indicate: lexical access difficulties syntactic difficulties discourse planning difficulties (Boschi et al. 2017).</p>"},{"location":"en/lingualab-text-production/#word-word-group-or-idea-repetitions","title":"Word, word group or idea repetitions","text":"<p>Words or content information that are present more than once in the sample (repetitions directly glued on top of each other or further apart in the sample). Total number of words, groups of words (combinations of 2 to 6 words) or content information present more than once in the sample. Could indicate: lexico-semantic deficits discourse planning difficulties (Boschi et al. 2017).</p>"},{"location":"en/lingualab-text-production/#variable-names","title":"Variable names","text":"<ul> <li><code>Nombre_de_lemmes</code></li> <li><code>Nombre_de_fragments</code></li> <li><code>Nombre_de_fragments_autre_methode</code></li> <li><code>Fragments_en_contexte</code></li> <li><code>Nombre_de_mots</code></li> <li><code>Nombre_de_lemmes_differents</code></li> <li><code>Nombre_de_pauses_silencieuses</code></li> <li><code>Nombre_de_pauses_remplies</code></li> <li><code>Nombre_de_repetitions_mots</code></li> </ul>"},{"location":"en/lingualab-text-semantic/","title":"Semantic features","text":""},{"location":"en/lingualab-text-semantic/#25-content-information-units-icus","title":"25 content information units (ICUs)","text":"<p>Separate subjects, places, objects and actions that are represented in the Cookie Theft image.</p> <p>The list of content units (ICUs) for the Cookie Theft image test as established by Yorkston and Beukelman (1980).</p> <p>The definition of ICUs can be found here</p>"},{"location":"en/lingualab-text-semantic/#total-number-of-icus","title":"Total number of ICUs","text":"<p>Total number of ICUs that appear in the sample. Total number of ICUs labeled as \"TRUE\".</p>"},{"location":"en/lingualab-text-semantic/#efficiency","title":"Efficiency","text":"<p>Ratio of the total length of the sample to the total number of ICUs present in the sample.</p>"},{"location":"en/lingualab-text-semantic/#idea-density","title":"Idea density","text":"<p>Average semantic similarity between (conceptually distinct) ideas transmitted within a window of words moved through the text.</p> <p>The average cosine distance (semantic similarity) between all pairs of word embeddings within a window moved through the text. Word embeddings will be extracted from the spaCy <code>en_core_web_lg</code> model, which supports syntactic dependency identification and Part-of-Speech tagging. Within a window, all cosine distances will be averaged. Windows of 3, 10, 25 and 40 words with an increment of half the window length will be implemented.</p>"},{"location":"en/lingualab-text-semantic/#variable-names","title":"Variable names","text":"<ul> <li><code>Nombre_ICU_TRUE</code></li> <li><code>Efficacite_ICU</code></li> <li>TODO</li> </ul>"},{"location":"en/lingualab-text-syntaxic/","title":"Syntactic features","text":""},{"location":"en/lingualab-text-syntaxic/#universal-syntactic-dependencies","title":"Universal syntactic dependencies","text":"<p>Universal syntactic dependencies are a set of rules that model grammatical relationships in languages. They are characterized by a hierarchical structure in which words are connected according to their syntactic function in a sentence. These rules are called \"universal\" because they are intended to be applicable across different languages, providing a common framework for linguistic analysis.</p> <p>The directional dependency relation is a specification of dependency grammar that establishes a connection between a syntactic unit (e.g. a verb) and the entities that make up its relational structure (such as subjects and objects). In a dependency tree, which is a graphical representation of these relationships, the words or morphemes are the nodes and the dependency relationships are the edges, often annotated with syntactic functions such as subject object, etc. https://fr.wikipedia.org/wiki/Grammaire_de_d\u00e9pendance </p> <p>Total number of each syntactic dependency: This means counting how many times each type of dependency relation (such as subject, object, complement, etc.) appears in a text.</p> <p>Calculation with spaCy dependencies (DEP): spaCy is able to analyze a sentence and identify these dependency relationships. Each word in a sentence is associated with a DEP tag that describes its syntactic role.</p> <p>Two calculation methods: - In absolute number: Count the total number of times a specific syntactic dependency appears. - In relation to the total number of words: Calculate the frequency of each syntactic dependency in relation to the total number of words in the sample, giving a relative measure.</p>"},{"location":"en/lingualab-text-syntaxic/#example","title":"Example","text":"<p>To illustrate the directional dependency relationship in syntax, let's consider the simple sentence: \"The cat eats a mouse.\"</p> <p>In a dependency tree for this sentence :</p> <ul> <li>\"eats\" would be the root because it's the verb, the main action of the sentence.</li> <li>\"The cat\" would be an actant, more precisely the subject of the verb \"eats\". There would therefore be a directional arrow starting from \"mange\" and pointing towards \"chat\", indicating that \"chat\" is the subject of \"mange\".</li> <li>A mouse\" would be another actant, the direct object of the verb \"mange\". Similarly, a directional arrow would run from \"mange\" to \"souris\" to indicate this relationship.</li> </ul> <p>In this tree, each word is connected by lines (or edges) that show how each word depends on the verb (or other words) for its syntactic function in the sentence.</p>"},{"location":"en/lingualab-text-syntaxic/#references","title":"References","text":"<ul> <li>Universal Dependencies</li> <li>https://spacy.io/usage/linguistic-features#dependency-parse</li> </ul>"},{"location":"en/lingualab-text-syntaxic/#length-of-syntax-dependencies","title":"Length of syntax dependencies","text":"<p>Average and maximum length of syntactic dependencies. Average and maximum number of words in a sample's syntactic dependencies.</p>"},{"location":"en/lingualab-text-syntaxic/#left-and-right-children","title":"Left and right children","text":"<p>Direct dependents of a word that are connected to it by a single arc to its left or right in the dependency tree.</p> <p>We measure the average number of left and right children for each word in a sample of texts. This helps us to understand the syntactic structure of the sentences in this sample.</p> <p>Calculated using spaCy commands <code>n_left</code> and <code>n_right</code> in two ways:</p> <ul> <li>as an absolute number</li> <li>in relation to the total number of words in the sample</li> </ul> <p>https://spacy.io/usage/linguistic-features#navigating |</p>"},{"location":"en/lingualab-text-syntaxic/#verbs-with-inflections-conjugated-verbs","title":"Verbs with inflections (conjugated verbs)","text":"<p>Verbs in the sample that do not match their lemma as extracted by spaCy.</p> <p>Calculated in two ways:</p> <ul> <li>in absolute number</li> <li>in relation to the total number of words in the sample</li> </ul>"},{"location":"en/lingualab-text-syntaxic/#subordinate-clauses","title":"Subordinate clauses","text":"<p>Group of words that does not express a complete thought, does not constitute a complete sentence. Complex clauses involving subordination occur when a syntactic dependent (main or not) is used as a causal structure.</p> <p>Total number of the 4 basic universal dependency types calculated using spaCy's default dependency parse:</p> <ul> <li>Clausal subjects (csubj)</li> <li>Clausal complements divided into those whose subject must be checked (subject outside the clause; <code>xcomp</code>) and those whose subject is not checked (subject inside the clause; <code>ccomp</code>).</li> <li>Adverbial clause modifiers (<code>advcl</code>)</li> <li>Adnominal clause modifiers (<code>acl</code>)</li> </ul> <p>Calculated in two ways:</p> <ul> <li>as an absolute number </li> <li>in relation to the total number of words in the sample</li> </ul> <p>https://universaldependencies.org/u/overview/complex-syntax.html</p>"},{"location":"en/lingualab-text-syntaxic/#average-sentence-length","title":"Average sentence length","text":"<p>Average number of words per sentence. The average number of words per sentence in the sample will be calculated. Sentence boundaries will be determined by spaCy's default \"dependency parse\".</p> <p>https://spacy.io/usage/linguistic-features#sbd</p>"},{"location":"en/lingualab-text-syntaxic/#incomplete-sentences","title":"Incomplete sentences","text":"<p>Phrases that do not contain a minimum of one verb and its subject. Total number of sentences in the sample that contain no verb with its subject.</p> <p>Calculated in two ways:</p> <ul> <li>in absolute numbers </li> <li>in relation to the total number of words in the sample</li> </ul> <p>Could indicate: lexical-semantic deficits, syntactic deficits, difficulties with discourse planning (Boschi et al. 2017).</p>"},{"location":"en/lingualab-text-syntaxic/#number-of-prepositional-phrases","title":"Number of prepositional phrases","text":"<p>Sentences that contain a preposition its object (noun or pronoun) and any object modifier, (Boschi et al. 2017).</p> <p>Calculated in the following two ways:</p> <ul> <li>in absolute number </li> <li>in relation to the total number of words in the sample</li> </ul>"},{"location":"en/lingualab-text-syntaxic/#number-of-verbal-phrases","title":"Number of verbal phrases","text":"<p>Basic sentences containing at least one verb and its dependents. Calculated using basic spaCy implementations.</p> <p>Calculated in two ways:</p> <ul> <li>absolute number </li> <li>in relation to the total number of words in the sample</li> </ul>"},{"location":"en/lingualab-text-syntaxic/#length-and-number-of-noun-phrases","title":"Length and number of noun phrases","text":"<p>A nominal phrase is a group of words centered around a noun (substantive) that functions as the subject, object or complement in a sentence. For example, in the sentence \"The black cat sleeps on the carpet\", \"The black cat\" is a noun phrase.</p> <p>The length of a nominal phrase is the number of words that make it up. It can vary from two words like \"A house\" to a longer sequence like \"The big house by the road\".</p> <p>Total number and average length of noun phrases in the sample. Calculated using basic spaCy implementations.</p> <p>Calculated in two ways:</p> <ul> <li>absolute number </li> <li>in relation to the total number of words in the sample</li> </ul> <p>https://spacy.io/usage/linguistic-features#noun-chunks</p>"},{"location":"en/lingualab-text-syntaxic/#verb-tenses-used","title":"Verb tenses used","text":"<p>Forms verbs take to indicate when the action takes place in time. Total number of verbs conjugated in the present, past and future tenses in the sample.</p> <p>Calculated in two ways:</p> <ul> <li>in absolute numbers </li> <li>in relation to the total number of words in the sample</li> </ul>"},{"location":"en/lingualab-text-syntaxic/#clauses-per-sentence","title":"Clauses per sentence","text":"<p>Groups of words comprising a subject and a verb normally used to add further details about a noun in a sentence. Average number of clauses per sentence calculated using basic spaCy implementations.</p>"},{"location":"en/lingualab-text-syntaxic/#proportion-of-nouns-with-determiners","title":"Proportion of nouns with determiners","text":"<p>Proportion of names for which a determiner is present. Number of names in the sample attached to a determiner out of the total number of names in the sample. Calculated using spaCy's dependency parse.</p>"},{"location":"en/lingualab-text-syntaxic/#coordinated-phrases","title":"Coordinated phrases","text":"<p>Phrases linked by one or more coordinating conjunctions. Total number of sentences in the sample containing the following coordinating conjunctions: \"and\", \"but\", \"for\", \"nor\", \"or\", \"yet\", \"so\" (Boschi et al. 2017).</p> <p>Calculated in the following two ways:</p> <ul> <li>in absolute numbers </li> <li>in relation to the total number of words in the sample</li> </ul>"},{"location":"en/lingualab-text-syntaxic/#variable-names","title":"Variable names","text":"<ul> <li><code>Longueur_moyenne_des_dependances</code></li> <li><code>Longueur_maximale_des_dependances</code></li> <li><code>Moyenne_enfants_gauches</code></li> <li><code>Moyenne_enfants_droits</code></li> <li><code>Total_enfants_gauches</code></li> <li><code>Total_enfants_droits</code></li> <li><code>Nombre_de_verbes_inflexion</code></li> <li><code>Verbe_inflection_relatif</code></li> <li><code>Sujets_Clausaux_absolu</code></li> <li><code>Sujets_Clausaux_relatif</code></li> <li><code>Complements_Clausaux_Controles_absolu</code></li> <li><code>Complements_Clausaux_Controles_relatif</code></li> <li><code>Complements_Clausaux_Non_Controles_absolu</code></li> <li><code>Complements_Clausaux_Non_Controles_relatif</code></li> <li><code>Modificateurs_Clauses_Adverbiaux_absolu</code></li> <li><code>Modificateurs_Clauses_Adverbiaux_relatif</code></li> <li><code>Modificateurs_Clauses_Adnominaux_absolu</code></li> <li><code>Modificateurs_Clauses_Adnominaux_relatif</code></li> <li><code>Longueur_moyenne_phrases</code></li> <li><code>Nombre_de_phrases_incompletes_absolu</code></li> <li><code>Nombre_de_phrases_incompletes_relatif</code></li> <li><code>Nombre_de_phrases_prepositionnelles_absolu</code></li> <li><code>Nombre_de_phrases_prepositionnelles_relatif</code></li> <li><code>Nombre_de_phrases_verbales_absolu</code></li> <li><code>Nombre_de_phrases_verbales_relatif</code></li> <li><code>Nombre_absolu_phrases_nominales</code></li> <li><code>Longueur_moyenne_phrases_nominales</code></li> <li><code>Frequence_relative_phrases_nominales</code></li> <li><code>Nbre_verb_present_absolu</code></li> <li><code>Nbre_verb_present_relatif</code></li> <li><code>Nbre_verb_past_absolu</code></li> <li><code>Nbre_verb_past_relatif</code></li> <li><code>Nbre_verb_future_absolu</code></li> <li><code>Nbre_verb_future_relatif</code></li> <li><code>Nbre_clauses_par_phrase</code></li> <li><code>Proportion_noms_determinants</code></li> <li><code>Nombre_de_phrases_coordonnees</code></li> <li><code>Frequence_relative_phrases_coordonnees</code></li> </ul>"},{"location":"features/audio-parselmouth/","title":"Parselmouth Praat features","text":"<p>The pipeline produces <code>population_lingualab_audio</code> which is an implementation of Parselmouth Praat Scripts in Python by David R. Feinberg</p> <p>This script will measure pitch, standard deviation of pitch, hnr, jitter, shimmer, and formants in python using parselmouth, a package that runs Praat in python.</p>"},{"location":"features/audio-parselmouth/#features-list","title":"Features list","text":"<ul> <li>F0_std</li> <li>duration</li> <li>f0_mean</li> <li>formants_1_mean</li> <li>formants_1_median</li> <li>formants_2_mean</li> <li>formants_2_median</li> <li>formants_3_mean</li> <li>formants_3_median</li> <li>formants_4_mean</li> <li>formants_4_median</li> <li>hnr</li> <li>jitter_ddp</li> <li>jitter_local</li> <li>jitter_local_absolute</li> <li>jitter_ppq5</li> <li>jitter_rap</li> <li>shimmer_apq11</li> <li>shimmer_apq3</li> <li>shimmer_apq5</li> <li>shimmer_dda</li> <li>shimmer_local</li> <li>shimmer_local_dB</li> </ul>"},{"location":"features/audio-uhmometer/","title":"Uhm-o-meter","text":"<p>The pipeline produces <code>population_uhmometer_metrics</code> which is an implementation of PRAAT scripts to measure fluency automatically</p> <p>It consists of two PRAAT scripts to measure fluency automatically. A rewritten praat script to measure silent pauses and articulation rate (original script syllable nuclei described in De Jong &amp; Wempe, 2009), and a new script to measure filled pauses. This new script is tested on Dutch and English L2 data.</p>"},{"location":"features/audio-uhmometer/#features-list","title":"Features list","text":"<ul> <li>nsyll</li> <li>npause</li> <li>dur(s)</li> <li>phonationtime(s)</li> <li>speechrate(nsyll/dur)</li> <li>articulation_rate(nsyll/phonationtime)</li> <li>ASD(speakingtime/nsyll)</li> </ul>"}]}